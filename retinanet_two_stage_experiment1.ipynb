{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Visual Relationship project\n",
    "This project is based on the [Google AI Open Images - Visual Relationship Track Kaggle Challenge](https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track).\n",
    "\n",
    "The challenge is to build the best performing algorithm for automatically detecting relationships triplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using COCO trained weights: resnet50_coco_best_v2.1.0.h5 from path: /home/powell/work/scpd/vision_project/visual_relationship/pretrained_models/resnet50_coco_best_v2.1.0.h5, downloaded from: https://github.com/fizyr/keras-retinanet/releases/download/0.5.0/resnet50_coco_best_v2.1.0.h5\n",
      "Keras version: 2.2.4\n",
      "Tensorflow version: 1.4.0\n",
      "Tensorflow lib config: /home/powell/ENTER/envs/carnd-term1/lib/python3.5/site-packages/tensorflow\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import wget\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "import collections\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import parallel \n",
    "import concurrent.futures\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import __version__ as keras_version\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Lambda, Cropping2D, Reshape, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# https://github.com/fizyr/keras-retinanet/blob/master/examples/ResNet50RetinaNet.ipynb\n",
    "import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image, compute_resize_scale\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "#def get_session():\n",
    "#    config = tf.ConfigProto()\n",
    "#    config.gpu_options.allow_growth = True\n",
    "#    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "#keras.backend.tensorflow_backend.set_session(get_session())\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "# https://github.com/fizyr/keras-retinanet/releases/download/0.5.0/resnet50_coco_best_v2.1.0.h5\n",
    "RCNN_COCO_MODEL_URL = \"https://github.com/fizyr/keras-retinanet/releases/download/0.5.0/resnet50_coco_best_v2.1.0.h5\"\n",
    "RCNN_COCO_MODEL = \"resnet50_coco_best_v2.1.0.h5\"\n",
    "\n",
    "# Local path to trained weights file\n",
    "MODEL_PATH = os.path.join(os.path.join(os.getcwd(), \"pretrained_models\"), RCNN_COCO_MODEL)\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print ('Downloading COCO trained weights: {} to path: {}'.format(RCNN_COCO_MODEL, MODEL_PATH))  \n",
    "    wget.download(RCNN_COCO_MODEL_URL, MODEL_PATH)  \n",
    "else:\n",
    "    print ('Using COCO trained weights: {} from path: {}, downloaded from: {}'.format(\n",
    "        RCNN_COCO_MODEL, MODEL_PATH, RCNN_COCO_MODEL_URL))\n",
    "    \n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "print ('Keras version: {}'.format(keras_version))\n",
    "print ('Tensorflow version: {}'.format(tf.__version__))\n",
    "print ('Tensorflow lib config: {}'.format(tf.sysconfig.get_lib()))\n",
    "\n",
    "from helpers import get_fid, process_labels_from_csv_input, process_raw_csv_input, get_data_dir_from_raw_single_dir \n",
    "from helpers import get_data_from_dir_recursive, bounding_box_to_plt, two_bounding_boxes_to_plt, show_images\n",
    "from helpers import show_given_images, show_random_images, _resize_job_helper, chunks, resize_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels loaded:61\n",
      "0: /m/078n6m-Coffee table\n",
      "1: /m/01mzpv-Chair\n",
      "2: /m/01226z-Football\n",
      "3: /m/0h2r6-Van\n",
      "4: /m/0pg52-Taxi\n",
      "5: /m/0cvnqh-Bench\n",
      "6: /m/0hg7b-Microphone\n",
      "7: /m/0dnr7-Textile\n",
      "8: /m/080hkjn-Handbag\n",
      "9: /m/01f91_-Pretzel\n",
      "10: /m/0k4j-Car\n",
      "11: /m/078jl-Snake\n",
      "12: /m/04_sv-Motorcycle\n",
      "13: /m/0bwd_0j-Elephant\n",
      "14: /m/02hj4-Dolphin\n",
      "15: /m/029bxz-Oven\n",
      "16: /m/019w40-Surfboard\n",
      "17: /m/01s55n-Suitcase\n",
      "18: /m/05r655-Girl\n",
      "19: /m/01yrx-Cat\n",
      "20: /m/05z87-Plastic\n",
      "21: /m/03k3r-Horse\n",
      "22: /m/050k8-Mobile phone\n",
      "23: /m/0fx9l-Microwave oven\n",
      "24: /m/0199g-Bicycle\n",
      "25: /m/0h8my_4-Tennis racket\n",
      "26: /m/04bcr3-Table\n",
      "27: /m/07y_7-Violin\n",
      "28: /m/04yx4-Man\n",
      "29: /m/0584n8-Briefcase\n",
      "30: /m/01599-Beer\n",
      "31: /m/09tvcd-Wine glass\n",
      "32: /m/0342h-Guitar\n",
      "33: /m/04dr76w-Bottle\n",
      "34: /m/0cmx8-Spoon\n",
      "35: /m/026t6-Drum\n",
      "36: /m/071p9-Ski\n",
      "37: /m/0bt9lr-Dog\n",
      "38: /m/08pbxl-Monkey\n",
      "39: /m/03bt1vf-Woman\n",
      "40: /m/01bl7v-Boy\n",
      "41: /m/0l14j_-Flute\n",
      "42: /m/04ctx-Knife\n",
      "43: /m/05r5c-Piano\n",
      "44: /m/0dv9c-Racket\n",
      "45: /m/01940j-Backpack\n",
      "46: /m/03ssj5-Bed\n",
      "47: /m/02jvh9-Mug\n",
      "48: /m/05ctyq-Tennis ball\n",
      "49: /m/01_5g-Chopsticks\n",
      "50: /m/03qrc-Hamster\n",
      "51: /m/06__v-Snowboard\n",
      "52: /m/04lbp-Leather\n",
      "53: /m/083vt-Wood\n",
      "54: /m/0dt3t-Fork\n",
      "55: /m/05_5p_0-Table tennis racket\n",
      "56: /m/0wdt60w-Rugby ball\n",
      "57: /m/03m3pdh-Sofa bed\n",
      "58: /m/0dv5r-Camera\n",
      "59: /m/02p5f1q-Coffee cup\n",
      "60: /m/01y9k5-Desk\n",
      "Number of unique labels from training data loaded: 61\n",
      "Number of unique labels from test data loaded: 59\n",
      "Total missing label count: 2\n",
      "/m/029bxz-Oven\n",
      "/m/0fx9l-Microwave oven\n"
     ]
    }
   ],
   "source": [
    "annotations_file='fullsize_train_annotations.csv'\n",
    "annotations_test_file='fullsize_test_annotations.csv'\n",
    "classes_file='fullsize_classes.csv'\n",
    "# Load the labels\n",
    "label_tag_to_name = process_labels_from_csv_input()\n",
    "def load_labels(label_tag_to_name, labels_file=classes_file):\n",
    "    labels_to_names = {}\n",
    "    # Process the labels info files and create a key value pair\n",
    "    with open(labels_file, encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            labels_to_names[int(row[1])]= (label_tag_to_name[row[0]], row[0])\n",
    "    return labels_to_names\n",
    "\n",
    "labels_to_names = load_labels(label_tag_to_name, labels_file=classes_file)\n",
    "#print(label_tag_to_name)\n",
    "print (\"Number of labels loaded:{}\".format(len(labels_to_names)))\n",
    "for k, v in sorted(labels_to_names.items()):\n",
    "    print (\"{}: {}-{}\".format(k, v[1], v[0]))\n",
    "\n",
    "def load_labels_and_dataset_from_data(label_tag_to_name, data_file=annotations_file):\n",
    "    labels_to_names = {}\n",
    "    # Process the labels info files and create a key value pair\n",
    "    with open(data_file, encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            \n",
    "            labels_to_names[row[-1]] = label_tag_to_name[row[-1]]\n",
    "    return labels_to_names\n",
    "\n",
    "train_labels_to_names = load_labels_and_dataset_from_data(label_tag_to_name, data_file=annotations_file)\n",
    "print (\"Number of unique labels from training data loaded: {}\".format(len(train_labels_to_names)))\n",
    "   \n",
    "test_labels_to_names = load_labels_and_dataset_from_data(label_tag_to_name, data_file=annotations_test_file)\n",
    "print (\"Number of unique labels from test data loaded: {}\".format(len(test_labels_to_names)))\n",
    "\n",
    "missing_label_set = set(train_labels_to_names.keys()) - set(test_labels_to_names.keys())\n",
    "print (\"Total missing label count: {}\".format(len(missing_label_set)))\n",
    "for l in missing_label_set:\n",
    "    print (\"{}-{}\".format(l, label_tag_to_name[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the inference data and prep it for next stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training y data size: 87547\n",
      "Test y data size: 40720\n"
     ]
    }
   ],
   "source": [
    "infer_result_dir_prefix = 'fullsize_infer_output'\n",
    "infer_train_result_dir = 'train_y_epoch50'\n",
    "infer_test_result_dir = 'test_y_epoch50'\n",
    "\n",
    "def load_y_data(prefix=infer_result_dir_prefix, y_data_dir=infer_train_result_dir):\n",
    "    cwd = os.getcwd()\n",
    "    flist = glob.glob(os.path.join(os.path.join(os.path.join(cwd, prefix), y_data_dir), '*.p.npy'))\n",
    "    y_data = {}\n",
    "    for f in flist:\n",
    "        fid = os.path.basename(f).split('.')[0]\n",
    "        assert fid not in y_data\n",
    "        y_data[fid] = np.load(f)\n",
    "    return y_data\n",
    "\n",
    "infer_y_train = load_y_data(prefix=infer_result_dir_prefix, y_data_dir=infer_train_result_dir)\n",
    "print (\"Training y data size: {}\".format(len(infer_y_train)))\n",
    "\n",
    "infer_y_test = load_y_data(prefix=infer_result_dir_prefix, y_data_dir=infer_test_result_dir)\n",
    "print (\"Test y data size: {}\".format(len(infer_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape on an example: (57, 6)\n",
      "Example 1 index: [  4.03687134e+02   3.80612610e+02   6.32968445e+02   5.21846008e+02\n",
      "   6.17850006e-01   5.00000000e+00]\n",
      "Image size: 96499\n",
      "Train and test len: 128267\n"
     ]
    }
   ],
   "source": [
    "k = list(infer_y_train.keys())[0]\n",
    "print (\"Shape on an example: {}\".format(infer_y_train[k].shape))\n",
    "print (\"Example 1 index: {}\".format(infer_y_train[k][0]))\n",
    "\n",
    "image_size_cache_file='image_size_cache.p'\n",
    "with open(image_size_cache_file, 'rb') as f:\n",
    "    image_size_cache = pickle.load(f)\n",
    "    \n",
    "# All images covered.\n",
    "print (\"Image size: {}\".format(len(image_size_cache)))\n",
    "print (\"Train and test len: {}\".format(len(infer_y_train) + len(infer_y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the training and test set for our model using\n",
    "\n",
    "Using the inference output and iterating over the inference output of training and test data\n",
    "create the training and test set for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the pickle files corresponding to the orignal train test set split.\n",
    "fullsize_train_model_file = 'fullsize_train_model.p'\n",
    "fullsize_test_model_file = 'fullsize_test_model.p'\n",
    "\n",
    "with open(fullsize_train_model_file, 'rb') as f:\n",
    "    fullsize_train_model_data = pickle.load(f)\n",
    "with open(fullsize_test_model_file, 'rb') as f:\n",
    "    fullsize_test_model_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of loaded data: dict_keys(['labels_orig', 'features', 'boxes'])\n",
      "Example 1: features: /home/powell/work/scpd/vision_project/visual_relationship/data/processed/raw/train_07/241d4c0143f2c91f.jpg\n",
      "Example 1: boxes: ['0', '0.88625', '0.4283019', '0.9981132', '0', '0.88625', '0.4283019', '0.9981132']\n",
      "Example 1: labels_orig: ('/m/04bcr3', '/m/083vt', 'is')\n",
      "Size of training set: 61965\n",
      "Size of test set: 32472\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the training dict and create training set\n",
    "print ('Keys of loaded data: {}'.format(fullsize_train_model_data.keys()))\n",
    "print ('Example 1: features: {}'.format(fullsize_train_model_data['features'][0]))\n",
    "print ('Example 1: boxes: {}'.format(fullsize_train_model_data['boxes'][0]))\n",
    "print ('Example 1: labels_orig: {}'.format(fullsize_train_model_data['labels_orig'][0]))\n",
    "\n",
    "def group_by_image(model_data):\n",
    "    image_group = {}\n",
    "    for image_path, boxes, labels in zip(model_data['features'], \n",
    "                                         model_data['boxes'],\n",
    "                                         model_data['labels_orig']):\n",
    "        fid = os.path.basename(image_path).split('.')[0]\n",
    "        if fid not in image_group:\n",
    "            image_group[fid] = {}\n",
    "\n",
    "        triplet = (labels[0], labels[1], labels[2])\n",
    "        if triplet not in image_group[fid]:\n",
    "            image_group[fid][triplet] = []\n",
    "            \n",
    "        image_group[fid][triplet].append(boxes)\n",
    "    image_group_triplet_sorted = {}\n",
    "    for k, v in image_group.items():\n",
    "        l = sorted(v.items(), key=lambda kv: len(kv[1]), reverse=True)\n",
    "        image_group_triplet_sorted[k] = [l[0]]  # Take the best triplet only :(\n",
    "    return image_group_triplet_sorted         \n",
    "\n",
    "        \n",
    "def create_dataset_from_infer(grouped_model_data, y_data, shape_restrict=(100, 6)):\n",
    "    dataset = {'id': [], 'features': [], 'boxes': [], 'labels_orig': [], \n",
    "               'label_subject_orig': [], 'label_object_orig': [], 'label_rel_orig': []}\n",
    "    for fid, triplet_list in grouped_model_data.items():\n",
    "        #assert fid not in y_data\n",
    "        labels = triplet_list[0][0]  # Most used triplet labels only\n",
    "        boxes = triplet_list[0][1]   # Most used triplet boxes only\n",
    "        if fid in y_data and y_data[fid].shape == shape_restrict:\n",
    "            dataset['id'].append(fid)\n",
    "            dataset['features'].append(y_data[fid].reshape(-1))\n",
    "            dataset['boxes'].append(np.asarray(boxes))\n",
    "            dataset['labels_orig'].append(labels)\n",
    "            dataset['label_subject_orig'].append(labels[0])\n",
    "            dataset['label_object_orig'].append(labels[1])\n",
    "            dataset['label_rel_orig'].append(labels[2])\n",
    "    return dataset\n",
    "\n",
    "model_train_grouped = group_by_image(model_data=fullsize_train_model_data)\n",
    "model_train_dataset = create_dataset_from_infer(grouped_model_data=model_train_grouped, y_data=infer_y_train)\n",
    "print ('Size of training set: {}'.format(len(model_train_dataset['id'])))\n",
    "\n",
    "model_test_grouped = group_by_image(model_data=fullsize_test_model_data)\n",
    "model_test_dataset = create_dataset_from_infer(grouped_model_data=model_test_grouped, y_data=infer_y_test)\n",
    "print ('Size of test set: {}'.format(len(model_test_dataset['id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training triplets length: 299\n",
      "Model test triplets length: 266\n"
     ]
    }
   ],
   "source": [
    "def get_triplets(model_grouped):\n",
    "    ret_dict = collections.defaultdict(int)\n",
    "    for k, v in model_grouped.items():\n",
    "        ret_dict[v[0][0]] += 1\n",
    "    return ret_dict\n",
    "\n",
    "model_train_triplet_dict = get_triplets(model_train_grouped)\n",
    "model_test_triplet_dict = get_triplets(model_test_grouped)\n",
    "\n",
    "print ('Model training triplets length: {}'.format(len(model_train_triplet_dict.keys())))\n",
    "print ('Model test triplets length: {}'.format(len(model_test_triplet_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training triplets length: 283\n",
      "Model test triplets length: 252\n",
      "Model training relationships: [('is', 30981), ('at', 15621), ('on', 5871), ('holds', 4100), ('plays', 2274), ('interacts_with', 1560), ('inside_of', 1082), ('hits', 279), ('wears', 188), ('under', 9)]\n",
      "Model test relationships: [('is', 15774), ('at', 9991), ('on', 2998), ('holds', 1681), ('plays', 970), ('interacts_with', 509), ('inside_of', 371), ('wears', 89), ('hits', 86), ('under', 3)]\n"
     ]
    }
   ],
   "source": [
    "def get_triplets_from_dataset(model_dataset):\n",
    "    ret_dict = collections.defaultdict(int)\n",
    "    rel_dict = collections.defaultdict(int)\n",
    "    for t in model_dataset['labels_orig']:\n",
    "        ret_dict[t] += 1\n",
    "        rel_dict[t[2]] += 1\n",
    "    return ret_dict, rel_dict\n",
    "\n",
    "model_train_triplet_dict, model_train_rel_dict = get_triplets_from_dataset(model_train_dataset)\n",
    "model_test_triplet_dict, model_test_rel_dict = get_triplets_from_dataset(model_test_dataset)\n",
    "\n",
    "print ('Model training triplets length: {}'.format(len(model_train_triplet_dict.keys())))\n",
    "print ('Model test triplets length: {}'.format(len(model_test_triplet_dict.keys())))\n",
    "\n",
    "print ('Model training relationships: {}'.format(sorted(model_train_rel_dict.items(), key=lambda kv: kv[1], reverse=True)))\n",
    "print ('Model test relationships: {}'.format(sorted(model_test_rel_dict.items(), key=lambda kv: kv[1], reverse=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size: 61965\n",
      "Test data set size: 32472\n",
      "Before Multi-Encoding feature shape: (600,), label: ('/m/01_5g', '/m/083vt', 'is'), label_subject: /m/01_5g,        label_object: /m/083vt, label_relationship: is\n",
      "After Multi-Encoding feature shape: (600,), subject label: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "MLB classes size object/subject: 61, classes: ['/m/01226z' '/m/01599' '/m/01940j' '/m/0199g' '/m/019w40' '/m/01_5g'\n",
      " '/m/01bl7v' '/m/01f91_' '/m/01mzpv' '/m/01s55n' '/m/01y9k5' '/m/01yrx'\n",
      " '/m/026t6' '/m/029bxz' '/m/02hj4' '/m/02jvh9' '/m/02p5f1q' '/m/0342h'\n",
      " '/m/03bt1vf' '/m/03k3r' '/m/03m3pdh' '/m/03qrc' '/m/03ssj5' '/m/04_sv'\n",
      " '/m/04bcr3' '/m/04ctx' '/m/04dr76w' '/m/04lbp' '/m/04yx4' '/m/050k8'\n",
      " '/m/0584n8' '/m/05_5p_0' '/m/05ctyq' '/m/05r5c' '/m/05r655' '/m/05z87'\n",
      " '/m/06__v' '/m/071p9' '/m/078jl' '/m/078n6m' '/m/07y_7' '/m/080hkjn'\n",
      " '/m/083vt' '/m/08pbxl' '/m/09tvcd' '/m/0bt9lr' '/m/0bwd_0j' '/m/0cmx8'\n",
      " '/m/0cvnqh' '/m/0dnr7' '/m/0dt3t' '/m/0dv5r' '/m/0dv9c' '/m/0fx9l'\n",
      " '/m/0h2r6' '/m/0h8my_4' '/m/0hg7b' '/m/0k4j' '/m/0l14j_' '/m/0pg52'\n",
      " '/m/0wdt60w']\n",
      "MLB classes size relationship: 10, classes: ['at' 'hits' 'holds' 'inside_of' 'interacts_with' 'is' 'on' 'plays' 'under'\n",
      " 'wears']\n",
      "Training data label set size: 61965\n",
      "Test data label set size: 32472\n"
     ]
    }
   ],
   "source": [
    "print ('Training data set size: {}'.format(len(model_train_dataset['features'])))\n",
    "print ('Test data set size: {}'.format(len(model_test_dataset['features'])))  \n",
    "\n",
    "classes_file='fullsize_classes.csv'\n",
    "label_tag_to_name = process_labels_from_csv_input()\n",
    "labels_to_names = load_labels(label_tag_to_name, labels_file=classes_file)\n",
    "\n",
    "print ('Before Multi-Encoding feature shape: {}, label: {}, label_subject: {}, \\\n",
    "       label_object: {}, label_relationship: {}'.format(model_train_dataset['features'][0].shape, \n",
    "                                                        model_test_dataset['labels_orig'][0],\n",
    "                                                        model_test_dataset['label_subject_orig'][0],\n",
    "                                                        model_test_dataset['label_object_orig'][0],\n",
    "                                                        model_test_dataset['label_rel_orig'][0]))\n",
    "\n",
    "# label encoding\n",
    "mlb_subject_object = LabelBinarizer()\n",
    "mlb_subject_object = mlb_subject_object.fit([ v[1] for k, v in labels_to_names.items() ])\n",
    "\n",
    "mlb_relationship = LabelBinarizer()\n",
    "mlb_relationship = mlb_relationship.fit(model_train_dataset['label_rel_orig'] + \n",
    "                                        model_test_dataset['label_rel_orig'])\n",
    "         \n",
    "# 1 hot vector encoding for subject/object\n",
    "model_train_dataset['label_subject'] = mlb_subject_object.transform(model_train_dataset['label_subject_orig'])\n",
    "model_test_dataset['label_subject'] = mlb_subject_object.transform(model_test_dataset['label_subject_orig'])\n",
    "model_train_dataset['label_object'] = mlb_subject_object.transform(model_train_dataset['label_subject_orig'])\n",
    "model_test_dataset['label_object'] = mlb_subject_object.transform(model_test_dataset['label_subject_orig'])\n",
    "\n",
    "# 1 hot vector encoding for relationship\n",
    "model_train_dataset['label_rel'] = mlb_relationship.transform(model_train_dataset['label_rel_orig'])\n",
    "model_test_dataset['label_rel'] = mlb_relationship.transform(model_test_dataset['label_rel_orig'])\n",
    "                  \n",
    "print ('After Multi-Encoding feature shape: {}, subject label: {}'.format(model_train_dataset['features'][0].shape, \n",
    "                                                                 model_train_dataset['label_subject'][0]))\n",
    "print('MLB classes size object/subject: {}, classes: {}'.format(len(mlb_subject_object.classes_), \n",
    "                                                                mlb_subject_object.classes_))\n",
    "print('MLB classes size relationship: {}, classes: {}'.format(len(mlb_relationship.classes_), \n",
    "                                                                mlb_relationship.classes_))\n",
    "print ('Training data label set size: {}'.format(len(model_train_dataset['label_subject'])))\n",
    "print ('Test data label set size: {}'.format(len(model_test_dataset['label_subject']))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling - Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (61965, 600)\n",
      "Boxes shape: (3, 8)\n",
      "Subject labels shape: (61,)\n",
      "Object labels shape: (61,)\n",
      "Relationship labels shape: (10,)\n",
      "Shape of y_test[0]: (61965,), y_test[1]: (61965,)\n",
      "Shape of X_test: (32472, 600)\n",
      "Shape of y_test[0]: (61965,), y_test[1]: (32472, 61), y_test[2]: (32472, 61), y_test[3]: (32472, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(model_train_dataset['features'])\n",
    "print('Shape of X_train: {}'.format(X_train.shape))\n",
    "print ('Boxes shape: {}'.format(model_train_dataset['boxes'][0].shape))\n",
    "print ('Subject labels shape: {}'.format(model_train_dataset['label_subject'][0].shape))\n",
    "print ('Object labels shape: {}'.format(model_train_dataset['label_object'][0].shape))\n",
    "print ('Relationship labels shape: {}'.format(model_train_dataset['label_rel'][0].shape))\n",
    "\n",
    "# Sequence of labels are boxes, subject, object and relationship\n",
    "y_train = [np.asarray(model_train_dataset['boxes']), \n",
    "           np.asarray(model_train_dataset['label_subject']),\n",
    "           np.asarray(model_train_dataset['label_object']),\n",
    "           np.asarray(model_train_dataset['label_rel'])]\n",
    "\n",
    "print('Shape of y_test[0]: {}, y_test[1]: {}'.format(y_train[0].shape, y_train[0].shape))\n",
    "X_test = np.asarray(model_test_dataset['features'])\n",
    "print('Shape of X_test: {}'.format(X_test.shape))\n",
    "y_test = [np.asarray(model_train_dataset['boxes']), \n",
    "          np.array(model_test_dataset['label_subject']),\n",
    "          np.array(model_test_dataset['label_object']),\n",
    "          np.array(model_test_dataset['label_rel'])]\n",
    "print('Shape of y_test[0]: {}, y_test[1]: {}, y_test[2]: {}, y_test[3]: {}'.format(\n",
    "    y_test[0].shape, y_test[1].shape, y_test[2].shape, y_test[3].shape))\n",
    "\n",
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train = std_scale.transform(X_train)\n",
    "X_test = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example train 1: [-1.01696422 -1.79809551  1.20471634  0.41640806  0.06793398  0.22155333\n",
      " -1.26574302 -1.13648349 -2.05116117 -0.92060461 -2.09424594  0.55740303\n",
      " -0.66521445  0.64935765  1.21009209  0.65268447 -2.23223657  0.09060562\n",
      " -0.13862309 -1.52785023 -0.93664668 -2.81823957 -2.24174002  0.42522784\n",
      " -1.27922797 -1.71267629  1.37458513  0.67941863 -2.14484275  2.31061881\n",
      "  0.5479121  -1.55601998 -0.19463816 -2.67219063 -2.10296688  0.56678568\n",
      "  1.68878874 -1.89939728  1.47320544 -1.93148381 -2.19203851  0.25429344\n",
      " -1.20466382 -1.62418405  1.40127899  0.74193608 -2.05567958 -1.52898255\n",
      " -1.34153193 -1.56477136 -1.52042357 -0.75131699 -1.91218657  0.46812317\n",
      "  0.82657018 -1.53439661  0.465729   -2.51576536 -1.83071423  2.2530004\n",
      "  0.52899768 -1.76948751 -0.04614441 -2.53390791 -1.71063187  0.46503331\n",
      " -1.26607208 -1.52990281 -1.6743018  -2.17637363 -1.66614861  0.47016536\n",
      " -1.36588172 -1.3233102  -2.04138762 -1.58097724 -1.8672585   0.60235605\n",
      " -0.9177636  -0.97480068  0.82532576  0.11383037 -1.81742441  0.16180136\n",
      " -0.58500823 -1.39571048 -1.05503843 -2.33344053 -1.78620232  2.25339994\n",
      " -0.76719727 -0.01948597  1.07648938  0.82207211 -1.76558375 -1.41773167\n",
      " -0.3445635  -1.62191167 -0.85563199 -2.28797687 -1.79883588  0.48919399\n",
      " -1.28382475 -1.55176854 -1.65427215 -2.09611132 -1.79733942  2.2504202\n",
      "  0.47462323 -1.64220057 -0.14890272 -2.37484895 -1.80487875  0.49149566\n",
      " -0.99978472 -0.57131897 -0.46470106  0.87644647 -1.79644676  0.16825837\n",
      " -1.37787719 -1.10627864 -1.8604047  -0.54904269 -1.77127706  0.42734796\n",
      "  0.48110943 -1.81970739 -0.0191883  -2.42682347 -1.74074057  2.24820576\n",
      " -0.38739332 -1.92714339 -0.82721364 -2.46586777 -1.75459702  0.49394366\n",
      "  2.2055195  -0.32333366  1.53074243 -0.88095966 -1.74219222 -1.39740476\n",
      " -0.58308028 -1.66893838  0.02101671 -2.33117669 -1.75414771  0.1739832\n",
      "  0.39887954 -1.5575805   1.30500793 -0.0629178  -1.73096858  0.17999951\n",
      " -1.33223132 -1.49796948 -0.93305491  0.82089326 -1.70200991  0.18589071\n",
      " -1.33584684 -1.50090552 -0.93213276  0.82933049 -1.66788355 -1.38932459\n",
      "  1.49423484 -0.28055449  1.53499146  0.92021302 -1.62587507  0.19139514\n",
      " -0.6177304  -1.45598825 -0.88490131 -2.22932928 -1.59883702  0.4955637\n",
      "  0.49324237 -1.83174333 -0.00699622 -2.32648449 -1.58045774  0.62302018\n",
      " -1.40520428 -1.42712903 -1.87614356 -0.60288947 -1.54935469  0.49811427\n",
      "  0.30111864 -0.42362578  1.44457638  0.93310249 -1.51336843  0.18586417\n",
      " -0.90006352 -1.14798239 -0.28607521  0.92136279 -1.48112524 -1.37635579\n",
      " -1.39995426 -1.54092239 -1.80869916 -1.82543627 -1.4782506   0.62977903\n",
      " -1.41028856 -1.7865102  -0.92404737 -0.17624504 -1.494413    0.48679798\n",
      "  2.03599263 -0.39632614  1.54653647 -1.04438619 -1.46311611 -1.37997506\n",
      "  2.1742043   0.29181461  1.53670832  0.08509827 -1.43672123  0.19575064\n",
      " -1.33027559 -1.72548946  1.46659952  0.94392211 -1.40725721  0.75021422\n",
      " -1.40289985 -1.5444129  -1.80834124 -1.80847892 -1.46521702  0.49752739\n",
      "  0.54366083 -1.75173696  0.45229589 -2.37381714 -1.46623762  2.25455652\n",
      " -1.4154326  -1.61295257  0.54719937 -0.62985211 -1.44338151  0.19539511\n",
      " -0.59840132 -1.52339064 -0.67472408 -2.25235951 -1.41956701  0.18756998\n",
      "  1.82862492 -0.48783558  1.56712518  0.47976374 -1.40004755  0.18410421\n",
      " -1.40683986 -1.04673215 -1.93359656 -0.89450161 -1.38932741  0.63548563\n",
      " -0.26150954 -1.61244046 -0.87086351 -2.24891304 -1.40018535  0.50702915\n",
      "  0.60944321 -1.81271747  0.1887441  -2.33419761 -1.3793118   0.50952957\n",
      " -0.869471    0.3252708  -0.65718588  0.98005812 -1.39841938  0.19487055\n",
      "  0.77278566 -1.62405472  0.51366921 -2.25689099 -1.39112937  0.5092836\n",
      " -1.29804817 -1.59239014 -1.62767528 -1.92864142 -1.36822123  1.50824573\n",
      " -1.30118108  0.42339425 -0.94485388  0.98971978 -1.37121863  0.19250375\n",
      "  0.351117   -1.89906048  0.89945184 -2.04029482 -1.36307306  0.19392115\n",
      "  0.2631162  -1.89788234 -0.12252159 -2.31165752 -1.3529285   0.50938596\n",
      " -1.38530459 -1.82876555 -1.33687636 -1.92710359 -1.33823769  2.24819872\n",
      " -0.81678519  0.5053373   1.33484593  0.99361562 -1.32249487  0.75984553\n",
      "  0.32160904 -1.94753711 -0.15839066 -2.34042376 -1.30505715  0.63498912\n",
      "  0.867653   -0.9662823   1.55360336  0.36934547 -1.28692125  0.19929798\n",
      "  0.2480489  -1.95026466 -0.33684193 -2.38348041 -1.26969299  0.50152159\n",
      "  2.18479548 -0.34908506  1.55900269 -1.06787642 -1.25043581 -1.36342957\n",
      " -0.62934534 -1.83496384  1.22516006 -1.15582181 -1.23604188  0.19465243\n",
      " -1.4248537  -1.83439284 -0.97183704 -1.43045208 -1.24410229  0.50550945\n",
      " -0.82829477 -0.08200423  1.13405832  0.98480114 -1.29969954 -1.4302148\n",
      " -1.44542418 -1.15777716 -1.81952837 -0.39620495 -1.28805372  0.18899599\n",
      "  1.54580737 -0.58457166  1.5502074  -0.47358116 -1.27424709  0.18852553\n",
      " -1.44034555 -1.68479806 -1.28619822 -0.27247584 -1.25653604  0.4468235\n",
      " -1.3080822  -1.61031243 -1.59974189 -1.88667794 -1.24477276  0.44779804\n",
      "  1.68329009 -2.04470343  1.57632188 -1.39192288 -1.2295192   1.07033472\n",
      "  2.04869985 -0.3988312   1.57702047 -0.11225444 -1.23200572 -1.35527411\n",
      " -1.39582548 -1.85276819  1.55288809  1.00190906 -1.21581525 -1.36006807\n",
      "  0.70229832 -1.83037871  0.33761564 -2.16446374 -1.20174188  0.51174832\n",
      "  0.13990687 -1.76442646  0.49871919 -2.1360255  -1.19357864  0.19555599\n",
      "  1.55249775 -2.0403644   1.58084955 -1.52496637 -1.19690007 -1.35188034\n",
      " -1.39303543 -1.8415698  -1.30808443 -1.88175997 -1.19051709  0.50630523\n",
      "  1.68239492 -2.02760276  1.57989457 -1.37764187 -1.17455097  1.00930368\n",
      " -1.10062588 -1.90701554 -0.36402984 -1.989151   -1.17917187  0.20060952\n",
      "  2.11368926 -0.37267885  1.57706328 -0.72345708 -1.16955753  1.62976363\n",
      "  0.3948801  -1.69356772 -0.07997195 -2.23370591 -1.15639516  0.44461954\n",
      " -0.80447596  0.30180863 -0.37018211  1.02776507 -1.15972185 -1.35414946\n",
      "  0.26318908 -1.93112943 -0.27360794 -2.34910625 -1.14730047  0.63810735\n",
      "  0.10855976 -2.04847913 -0.38027334 -2.31152352 -1.14422462  0.51374489\n",
      " -1.38947712 -1.89696691  1.48464555  1.0155842  -1.13507031  1.43567939\n",
      "  2.06863338 -0.3211319   1.57737434  0.01277899 -1.12867514  0.19831698\n",
      "  1.99020681 -0.5774845   1.56927344 -1.19534506 -1.11543385 -1.35958278\n",
      " -0.72004996  1.03700169  1.05492268  1.04669382 -1.11071379 -1.3509885\n",
      " -0.4747576  -1.55755184 -0.21742226 -2.17914606 -1.10270484  0.20645287\n",
      " -1.33798649 -1.61353882 -1.5825389  -1.86108056 -1.09318205  0.63450273\n",
      "  0.70961955 -1.63902388  0.56572775 -2.17345571 -1.12058032  1.50039991\n",
      " -1.43816348 -1.56913066 -1.77682591 -1.69405333 -1.15112557  0.44475362\n",
      " -0.6376329  -1.54102782 -0.86181887 -2.21943137 -1.15883521  2.24637668\n",
      " -1.44412002 -1.42923571 -1.92050655 -1.48383341 -1.1602933   0.50190008\n",
      " -0.31483192 -1.73480268 -0.78865758 -2.24787012 -1.14991054  0.44696509\n",
      "  0.41788732 -1.90140052 -0.12415554 -2.38807383 -1.14129021  0.63064786\n",
      "  2.08703229  0.14493112  1.58519684  0.25671952 -1.12993942 -1.35084516\n",
      " -0.20006305 -1.94537713 -0.73817584 -2.46550115 -1.12619937  0.50973956\n",
      " -1.01543468 -0.92563212  0.11496868  0.98481412 -1.11791553 -1.41311589\n",
      " -0.73708832 -1.54809422 -1.05433555 -1.90534382 -1.10899863  0.51048927\n",
      " -1.45143012 -1.68592747 -1.26415492 -0.21862244 -1.12803298  0.20405544\n",
      " -0.52308324 -1.54942394 -0.62641946 -2.11716952 -1.12182933  0.50701292\n",
      " -0.83749387  0.48133422  1.36573244  1.06540332 -1.11104995  2.29248981\n",
      " -0.50001372 -2.03671528 -0.71523389 -2.4954397  -1.10218197  0.3199064 ]\n",
      "Example test boxes 1: [['0.96' '0.99875' '0.38166666' '0.48833334' '0.96' '0.99875' '0.38166666'\n",
      "  '0.48833334']\n",
      " ['0.07625' '0.1125' '0.45666668' '0.49166667' '0.07625' '0.1125'\n",
      "  '0.45666668' '0.49166667']\n",
      " ['0.5425' '0.6475' '0.045' '0.15166667' '0.5425' '0.6475' '0.045'\n",
      "  '0.15166667']]\n",
      "Example test subject labels: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example test object labels: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example test relationship labels: [0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print ('Example train 1: {}'.format(X_train[0]))\n",
    "print ('Example test boxes 1: {}'.format(y_train[0][0]))\n",
    "print ('Example test subject labels: {}'.format(y_train[1][0]))\n",
    "print ('Example test object labels: {}'.format(y_train[2][0]))\n",
    "print ('Example test relationship labels: {}'.format(y_train[3][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PriorProbability(keras.initializers.Initializer):\n",
    "    \"\"\" Apply a prior probability to the weights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, probability=0.01):\n",
    "        self.probability = probability\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'probability': self.probability\n",
    "        }\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        # set bias to -log((1 - p)/p) for foreground\n",
    "        result = np.ones(shape, dtype=dtype) * -math.log((1 - self.probability) / self.probability)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DeepClassifyRegressModel(input_shape, subject_output_class_size, object_output_class_size,\n",
    "                             relationship_output_class_size,\n",
    "                             output_reg_size, prior_probability = 0.01, \n",
    "                             drop_out=0.5,\n",
    "                             disable_regress=True):\n",
    "    \"\"\"\n",
    "    Model is regular deep neural network with 4 outputs.\n",
    "    output1: Regression with two bounding boxes of size (N, 4)\n",
    "    output2: Object classifcation of size(N, 61)\n",
    "    output3: Subject classifcation of size(N, 61)\n",
    "    output3: Relationship classifcation of size(N, 10)\n",
    "    \"\"\"\n",
    "    main_input = Input(shape=input_shape)\n",
    "\n",
    "    # Layer 1 Relu - Norm - Dropout\n",
    "    if disable_regress is False:\n",
    "        bias_initializer=PriorProbability(probability=prior_probability)\n",
    "    else:\n",
    "        bias_initializer='zeros'\n",
    "    shared_model = Dense(units=1024, input_shape=input_shape, \n",
    "                        kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
    "                        bias_initializer=bias_initializer)(main_input)                   \n",
    "    shared_model = BatchNormalization()(shared_model)\n",
    "    shared_model = Activation('relu')(shared_model)\n",
    "    shared_model = Dropout(drop_out)(shared_model)\n",
    "\n",
    "    # Layer 2\n",
    "    if disable_regress is False:\n",
    "        bias_initializer=PriorProbability(probability=prior_probability)\n",
    "    shared_model = Dense(units=256,\n",
    "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
    "                         bias_initializer=PriorProbability(probability=prior_probability))(shared_model)\n",
    "    shared_model = BatchNormalization()(shared_model)\n",
    "    shared_model = Activation('relu')(shared_model)\n",
    "    shared_model = Dropout(drop_out)(shared_model)\n",
    "    \"\"\"\n",
    "    # Layer 3\n",
    "    if disable_regress is False:\n",
    "        bias_initializer=PriorProbability(probability=prior_probability)\n",
    "    shared_model = Dense(units=128,\n",
    "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
    "                         bias_initializer=PriorProbability(probability=prior_probability))(shared_model)\n",
    "    shared_model = BatchNormalization()(shared_model)\n",
    "    shared_model = Activation('relu')(shared_model)\n",
    "    shared_model = Dropout(drop_out)(shared_model)\n",
    "    \"\"\"\n",
    "\n",
    "    # Regression branch\n",
    "    model_regression = None\n",
    "    if disable_regress is False:\n",
    "        model_regression = Dense(output_reg_size, activation=\"linear\", name=\"regression\")(shared_model)\n",
    "    \n",
    "    # Subject classification branch\n",
    "    model_subject_classify = Dense(subject_output_class_size)(shared_model)\n",
    "    model_subject_classify = Activation(tf.nn.softmax, name=\"classification_subject\")(model_subject_classify)\n",
    "    \n",
    "    # Object classification branch\n",
    "    model_object_classify = Dense(object_output_class_size)(shared_model)\n",
    "    model_object_classify = Activation(tf.nn.softmax, name=\"classification_object\")(model_object_classify)\n",
    "    \n",
    "    # 2 Layer for relationship, everything is the input\n",
    "\n",
    "    if disable_regress is False:\n",
    "        concat_layer = concatenate([model_regression, model_subject_classify, model_object_classify], axis=1)\n",
    "    else:\n",
    "        concat_layer = concatenate([shared_model, model_subject_classify, model_object_classify], axis=1)\n",
    "\n",
    "\n",
    "    if disable_regress is False:\n",
    "        bias_initializer=PriorProbability(probability=prior_probability)\n",
    "    relationship_model = Dense(units=64,\n",
    "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
    "                         bias_initializer=PriorProbability(probability=prior_probability))(concat_layer)\n",
    "    relationship_model = BatchNormalization()(relationship_model)\n",
    "    relationship_model = Activation('relu')(relationship_model)\n",
    "    relationship_model = Dropout(drop_out)(relationship_model)\n",
    "\n",
    "    model_relationship_classify = Dense(relationship_output_class_size)(relationship_model)\n",
    "    model_relationship_classify = Activation(tf.nn.softmax, \n",
    "                                             name=\"classification_relationship\")(model_relationship_classify)\n",
    "    \n",
    "    outputs=[]\n",
    "    if model_regression is not None:\n",
    "        outputs=[model_regression]\n",
    "    model = Model(inputs=[main_input], outputs= outputs + [model_subject_classify, \n",
    "                                                model_object_classify, model_relationship_classify])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Compatible with tensorflow backend\n",
    "\n",
    "our_model.compile(optimizer=optimizer, loss=[focal_loss(alpha=.25, gamma=2)])\n",
    "'''\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_retinanet import losses\n",
    "def train_model(model, x_train, y_train, learn_rate=1e-5, epochs=32, batch_size=64, \n",
    "                disable_regress = True, verbose=1):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    Using as loss function and Adam optimizer\n",
    "    \"\"\"\n",
    "    loss_dict = {'classification_subject': 'categorical_crossentropy', # focal_loss()\n",
    "            'classification_object': 'categorical_crossentropy', # focal_loss() \n",
    "            'classification_relationship': 'categorical_crossentropy', # focal_loss()\n",
    "                }\n",
    "    if disable_regress is False:\n",
    "       loss_dict['regression'] = 'mean_squared_error'\n",
    "    \n",
    "    model.compile(loss=loss_dict,\n",
    "        optimizer=keras.optimizers.adam(lr=learn_rate, clipnorm=0.001), metrics=['accuracy'])\n",
    "    return model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "        verbose=verbose, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (600,)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1024)         615424      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1024)         4096        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1024)         0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1024)         0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 256)          262400      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256)          1024        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 61)           15677       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 61)           15677       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "classification_subject (Activat (None, 61)           0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classification_object (Activati (None, 61)           0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 378)          0           dropout_10[0][0]                 \n",
      "                                                                 classification_subject[0][0]     \n",
      "                                                                 classification_object[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 64)           24256       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64)           256         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64)           0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64)           0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 10)           650         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "classification_relationship (Ac (None, 10)           0           dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 939,460\n",
      "Trainable params: 936,772\n",
      "Non-trainable params: 2,688\n",
      "__________________________________________________________________________________________________\n",
      "Train on 49572 samples, validate on 12393 samples\n",
      "Epoch 1/10\n",
      "49572/49572 [==============================] - 82s 2ms/step - loss: 8.8984 - classification_subject_loss: 3.4650 - classification_object_loss: 3.2756 - classification_relationship_loss: 2.1579 - classification_subject_acc: 0.2045 - classification_object_acc: 0.2186 - classification_relationship_acc: 0.2780 - val_loss: 6.5944 - val_classification_subject_loss: 2.4732 - val_classification_object_loss: 2.4239 - val_classification_relationship_loss: 1.6973 - val_classification_subject_acc: 0.3922 - val_classification_object_acc: 0.3897 - val_classification_relationship_acc: 0.4493\n",
      "Epoch 2/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 6.6279 - classification_subject_loss: 2.4667 - classification_object_loss: 2.4233 - classification_relationship_loss: 1.7379 - classification_subject_acc: 0.3305 - classification_object_acc: 0.3323 - classification_relationship_acc: 0.4075 - val_loss: 5.6510 - val_classification_subject_loss: 2.0995 - val_classification_object_loss: 2.0889 - val_classification_relationship_loss: 1.4626 - val_classification_subject_acc: 0.4093 - val_classification_object_acc: 0.4122 - val_classification_relationship_acc: 0.4898\n",
      "Epoch 3/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 6.1148 - classification_subject_loss: 2.2698 - classification_object_loss: 2.2538 - classification_relationship_loss: 1.5913 - classification_subject_acc: 0.3419 - classification_object_acc: 0.3437 - classification_relationship_acc: 0.4478 - val_loss: 5.2448 - val_classification_subject_loss: 1.9595 - val_classification_object_loss: 1.9613 - val_classification_relationship_loss: 1.3240 - val_classification_subject_acc: 0.4223 - val_classification_object_acc: 0.4191 - val_classification_relationship_acc: 0.5279\n",
      "Epoch 4/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 5.8661 - classification_subject_loss: 2.1812 - classification_object_loss: 2.1695 - classification_relationship_loss: 1.5153 - classification_subject_acc: 0.3538 - classification_object_acc: 0.3552 - classification_relationship_acc: 0.4691 - val_loss: 5.0650 - val_classification_subject_loss: 1.8963 - val_classification_object_loss: 1.8918 - val_classification_relationship_loss: 1.2769 - val_classification_subject_acc: 0.4279 - val_classification_object_acc: 0.4271 - val_classification_relationship_acc: 0.5313\n",
      "Epoch 5/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 5.6923 - classification_subject_loss: 2.1201 - classification_object_loss: 2.1074 - classification_relationship_loss: 1.4649 - classification_subject_acc: 0.3624 - classification_object_acc: 0.3650 - classification_relationship_acc: 0.4770 - val_loss: 4.9504 - val_classification_subject_loss: 1.8599 - val_classification_object_loss: 1.8558 - val_classification_relationship_loss: 1.2347 - val_classification_subject_acc: 0.4299 - val_classification_object_acc: 0.4337 - val_classification_relationship_acc: 0.5412\n",
      "Epoch 6/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 5.5674 - classification_subject_loss: 2.0765 - classification_object_loss: 2.0656 - classification_relationship_loss: 1.4254 - classification_subject_acc: 0.3713 - classification_object_acc: 0.3733 - classification_relationship_acc: 0.4821 - val_loss: 4.8602 - val_classification_subject_loss: 1.8310 - val_classification_object_loss: 1.8268 - val_classification_relationship_loss: 1.2025 - val_classification_subject_acc: 0.4368 - val_classification_object_acc: 0.4346 - val_classification_relationship_acc: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 5.4674 - classification_subject_loss: 2.0388 - classification_object_loss: 2.0314 - classification_relationship_loss: 1.3973 - classification_subject_acc: 0.3771 - classification_object_acc: 0.3746 - classification_relationship_acc: 0.4901 - val_loss: 4.8162 - val_classification_subject_loss: 1.8114 - val_classification_object_loss: 1.8092 - val_classification_relationship_loss: 1.1956 - val_classification_subject_acc: 0.4386 - val_classification_object_acc: 0.4370 - val_classification_relationship_acc: 0.5419\n",
      "Epoch 8/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 5.3664 - classification_subject_loss: 2.0009 - classification_object_loss: 1.9985 - classification_relationship_loss: 1.3670 - classification_subject_acc: 0.3831 - classification_object_acc: 0.3818 - classification_relationship_acc: 0.4978 - val_loss: 4.7549 - val_classification_subject_loss: 1.7888 - val_classification_object_loss: 1.7890 - val_classification_relationship_loss: 1.1771 - val_classification_subject_acc: 0.4419 - val_classification_object_acc: 0.4400 - val_classification_relationship_acc: 0.5454\n",
      "Epoch 9/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 5.3089 - classification_subject_loss: 1.9834 - classification_object_loss: 1.9786 - classification_relationship_loss: 1.3469 - classification_subject_acc: 0.3834 - classification_object_acc: 0.3881 - classification_relationship_acc: 0.5030 - val_loss: 4.7308 - val_classification_subject_loss: 1.7787 - val_classification_object_loss: 1.7781 - val_classification_relationship_loss: 1.1740 - val_classification_subject_acc: 0.4399 - val_classification_object_acc: 0.4378 - val_classification_relationship_acc: 0.5489\n",
      "Epoch 10/10\n",
      "49572/49572 [==============================] - 81s 2ms/step - loss: 5.2450 - classification_subject_loss: 1.9554 - classification_object_loss: 1.9551 - classification_relationship_loss: 1.3344 - classification_subject_acc: 0.3921 - classification_object_acc: 0.3920 - classification_relationship_acc: 0.5061 - val_loss: 4.6992 - val_classification_subject_loss: 1.7677 - val_classification_object_loss: 1.7651 - val_classification_relationship_loss: 1.1664 - val_classification_subject_acc: 0.4382 - val_classification_object_acc: 0.4400 - val_classification_relationship_acc: 0.5504\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "print (\"Input shape: {}\".format(X_train[0].shape))\n",
    "disable_regress = True\n",
    "model = DeepClassifyRegressModel(X_train[0].shape, subject_output_class_size=len(mlb_subject_object.classes_),\n",
    "                                 object_output_class_size=len(mlb_subject_object.classes_), \n",
    "                                 relationship_output_class_size=len(mlb_relationship.classes_),\n",
    "                                 output_reg_size=8,\n",
    "                                 disable_regress=disable_regress)\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "if disable_regress:\n",
    "    y_train_final = y_train[1:]   # Remove the regression y data.\n",
    "\n",
    "model_history = train_model(model, X_train, y_train_final, epochs=epochs, batch_size=batch_size, \n",
    "                            disable_regress=disable_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "Save the model that has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the weights.\n",
    "model.save_weights('stage2_model_epoch_10_weights.h5')\n",
    "model.save('stage2_model_epoch_10.h5')\n",
    "\n",
    "# Save the model architecture.\n",
    "with open('stage2_model.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "    \n",
    "# Save the MLB labels for later use.\n",
    "with open(\"mlb_subject_object.p\", \"wb\") as f:\n",
    "    f.write(pickle.dumps(mlb_subject_object))\n",
    "    \n",
    "with open(\"mlb_relationship.p\", \"wb\") as f:\n",
    "    f.write(pickle.dumps(mlb_relationship))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History keys: dict_keys(['classification_relationship_loss', 'classification_subject_loss', 'classification_subject_acc', 'classification_object_loss', 'val_classification_subject_loss', 'val_classification_subject_acc', 'loss', 'val_classification_relationship_loss', 'val_classification_relationship_acc', 'val_classification_object_acc', 'classification_object_acc', 'val_classification_object_loss', 'val_loss', 'classification_relationship_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEaCAYAAAD5fVeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd4VFX6wPHvnZ7eJp0aEmoooRiK\nKF2l2VFZUIrKWhZXXUTd/S2rIqKAqKu7YoMVUVj7iiBV6UqH0ImEUBJKEhLS29zfHxMmGQhhEpJM\nMvN+nmeeyczcmfvOYXjPveece46iqqqKEEIIt6JxdgBCCCHqnyR/IYRwQ5L8hRDCDUnyF0IINyTJ\nXwgh3JAkfyGEcEOS/AUAhw4dQlEUtm/fXq33hYWFMXv27DqKyn29//77eHt7OzsM4cIk+TcSiqJU\neWvRosV1fX5MTAypqal06dKlWu9LSEjg8ccfv659O0oqmsqtW7cOrVZL3759nR2KaEQk+TcSqamp\nttvXX38NwM6dO23Pbdu2rdL3FRUVOfT5Wq2WsLAwdDpdteIKDg7G09OzWu8RtWvevHn86U9/Ys+e\nPRw8eNDZ4QCO/+6E80jybyTCwsJst8DAQMCaeC89FxwcbNvupZde4tFHHyUwMJDBgwcDMHv2bDp1\n6oSXlxcRERGMGTOGc+fO2T7/8mafS4+/+eYbbrvtNjw9PYmOjubzzz+/Iq6KR+NhYWG8+uqrPPHE\nE/j7+xMWFsbUqVOxWCy2bXJzc5kwYQK+vr4EBgYyefJknn32WWJjY6+rjPbv38+tt96Kl5cXPj4+\n3HHHHRw/ftz2+oULFxg7diyhoaEYjUaaN2/OCy+8YHv9559/plevXnh7e+Pr60tcXBw///zzVfd3\n9OhR7rjjDsLCwvD09KRz584sWbLEbpuePXvyxBNP8Pe//52QkBCCgoKYOHEieXl5tm1KS0uZOnUq\nZrMZHx8f/vCHP3Dx4kWHvnN6ejrffvstTzzxBHfffTcffPDBFdtcvHiRJ598ksjISIxGI1FRUXb/\nZqmpqTz44IOEhIRgMplo27Ytn332GQA//fQTiqKQlpZm276kpARFUVi8eDFQ/ltZsmQJQ4YMwdPT\nk1dffZXi4mImTpxIVFQUHh4etGrVimnTplFcXGwX3/Lly+nduzeenp74+/vTv39/Tpw4wU8//YTB\nYODs2bN223/wwQcEBQVRWFjoUBmJyknyd0Fz5syhRYsW/Pbbb8ybNw+wNhu99dZb7Nu3jy+//JIj\nR44wduzYa37W1KlTeeSRR9i7dy933HEH48aNs0uoV9t/VFQU27Zt480332T27Nl88cUXtteffvpp\nVqxYweLFi9m8eTN6vZ6PPvrour5zTk4OgwcPRlEUNm7cyNq1a0lLS2Po0KGUlJTYvsvBgwdZunQp\nR44cYdGiRcTExABQWFjIyJEjufnmm9m9ezfbt2/nb3/7GyaT6ar7zM7O5pZbbmHlypUkJCTw0EMP\nMXr0aDZv3my33aJFiygsLGTDhg0sXLiQL7/8krlz59penz17Nv/+9795++232bFjB+3bt+fVV191\n6HsvWLCArl27EhMTw7hx4/j0008pKCiwvW6xWLj11ltZuXIl8+bN4+DBg3z88ce2A4icnBz69u3L\noUOHWLx4MQcOHGDu3LkYjUbHCr6C5557jgkTJrB//37Gjx9PaWkpkZGRLF68mIMHDzJ79mz+9a9/\n2VU8y5YtY/jw4fTp04dff/2VzZs388ADD1BcXMyQIUOIjIxkwYIFdvv58MMPefDBB2sUo6hAFY3O\nzz//rALqyZMnr3gtNDRUHTp06DU/Y/PmzSqgpqWlqaqqqgcPHlQBddu2bXaP33vvPdt7CgsLVYPB\noC5YsMBuf7NmzbJ7fO+999rtq1+/fuq4ceNUVVXVjIwMVafTqZ999pndNp07d1Y7dOhQZcyX76ui\nd999V/Xx8VEvXLhge+7kyZOqXq9XlyxZoqqqqg4ZMkSdNGlSpe9PSUlRAXXLli1VxnAtQ4YMUZ98\n8knb4/j4eLVHjx5224wbN07t16+f7bHZbFZffvllu22GDRumenl5XXN/bdq0UT/44ANVVVXVYrGo\nLVq0UBcuXGh7fenSpSqg7t27t9L3v/vuu6qXl5d65syZSl9fvny5Cqjnz5+3PVdcXKwC6hdffKGq\navlv5Y033rhmvDNmzFBjY2Ntj7t3767efffdV93+1VdfVaOjo1WLxaKqqqru3r1bBdT9+/dfc1+i\nanLk74JuuOGGK55bvXo1gwcPpmnTpvj4+DBo0CAAkpOTq/ysih3ABoMBs9l8xWl4Ve8BiIiIsL3n\nyJEjlJSU0LNnT7ttevXqVeVnXsv+/fvp1KkT/v7+tueaNGlCVFQU+/fvB+DJJ5/k008/pXPnzjzz\nzDOsXLkStWxew/DwcMaMGUO/fv0YNmwYb7zxBomJiVXuMycnhylTptC+fXsCAgLw9vZm7dq1V5Rp\nVeVx7tw50tLS6N27t902N9544zW/87p16zhx4gT33XcfYD27e/DBB21newA7duwgPDycjh07VvoZ\nO3bsoFOnToSGhl5zf9dS2e/uX//6Fz169CAkJARvb29eeuklW/moqsquXbsYMmTIVT9zwoQJJCcn\n88svvwDWo/4+ffrQvn37647X3Unyd0FeXl52jxMTExk+fDht2rRhyZIlbN++nS+//BK4dsecwWCw\ne6woil37fU3foyhKlZ9RF0aMGMGJEyd47rnnuHjxIvfddx+33HKLLbaFCxeydetW+vfvz5o1a2jf\nvv0VTQ4VPfXUU3z55Ze8/PLL/PLLL+zevZuBAwdeUaY1KUNHzJs3j/z8fAIDA9HpdOh0OqZPn87G\njRtrreNXo7GmCLXC5L+Xt9lfcvnvbuHChTzzzDOMHTuW5cuXs2vXLqZOnVqtzuCwsDBuv/12Pvzw\nQ/Lz81m0aBGPPvpoDb6JuJwkfzfw22+/UVxczFtvvUXv3r1p06YNZ86ccUosrVu3RqfTsWXLFrvn\nf/311+v63A4dOrB3714yMzNtz506dYpjx47ZdSSbzWb+8Ic/8NFHH/Htt9+yatUqfv/9d9vrnTp1\n4i9/+QsrVqxg9OjRfPjhh1fd5/r163nooYe455576Ny5My1atODo0aPVivtSJ/Dl/QSbNm2q8n3p\n6el88803fPjhh+zevdt227NnD/Hx8baO327dupGamkpCQkKln9OtWzf27t171bO5kJAQAFJSUmzP\n7dy506Hvtn79euLj45k8eTLdunUjJiaGpKQk2+uKohAXF8fKlSur/JxJkybxzTff2M5o7r33Xof2\nL6omyd8NtG7dGovFwty5c0lKSuLrr7/mtddec0osAQEBjB8/nqlTp7J8+XIOHz7MlClTSEpKcuhs\nICUlxS7Z7d69m9OnT/PQQw/h7e3NAw88wK5du9i2bRv3338/0dHR3HnnnYC1w/e7777jyJEjHD58\nmC+++AJfX18iIyM5cOAAL774Ips2bSI5OZlNmzaxZcuWKpsX2rRpwzfffMOOHTvYv38/EyZMsBsV\n46hnn33W1il+9OhRXnvtNdavX1/lexYsWICHhwcPPvggsbGxdrfRo0fbOn5vvfVWbrjhBu6++26W\nLl1KUlISGzZsYP78+QC2UT4jRoxg7dq1JCUlsWrVKr766isA2rVrR0REBH//+985fPgw69at47nn\nnnPoe7Vp04adO3fy448/kpiYyOzZs1m6dKndNn//+9/55ptvmDJlCgkJCRw6dIiPP/7YrkIeOHAg\nTZs2ZerUqYwZMwYPD4/qFK+4Ckn+bqBHjx68+eabvP3227Rv355//vOfdqNN6tvcuXMZPHgwo0aN\nolevXhQVFTF69OgqR9ZUfG9cXJzdbdasWXh7e7Nq1SosFgs33ngjAwYMICgoiGXLltmuXTAYDPz1\nr38lLi6O+Ph4jh49yooVK/D09MTHx4cDBw4watQoWrduzahRoxgwYABvvvnmVWP55z//SUhICDfd\ndBODBw+mdevWjBgxotrl8dxzz/Hoo4/y5JNPEhcXx549e3jxxRerfM+HH37IHXfccUWTEliPjDMz\nM/nqq6/QarWsWLGCgQMH8vDDD9O2bVvGjRvHhQsXAPDx8WHDhg1ER0dz77330q5dOyZPnmwbRmk0\nGlmyZAnJycl06dKFP//5z7z++usOfa8//elP3HvvvYwZM8Z2hvG3v/3NbpsRI0bwv//9j3Xr1tGj\nRw969uzJ559/jl6vt22jKAoPP/wwRUVF0uRTixRVlZW8hPP17t2bli1bsmjRImeHIhqgyZMns23b\ntiuaC0XNVe9yTiFqwa5du9i/fz/x8fEUFBTwySefsGXLFofHtgv3kZWVxYEDB/jkk0/45JNPnB2O\nS5HkL5zinXfe4dChQ4C1XfnHH3+kf//+To5KNDS33HILe/fuZezYsdLRW8uk2UcIIdyQdPgKIYQb\nkuQvhBBuqEG3+Ve8sKQ6zGZzjcZbuyIpC3tSHvakPMq5QllEREQ4vG29Jf9ly5axZs0aVFVl4MCB\nDBs2rL52LYQQ4jL10uxz4sQJ1qxZw4wZM5g1axY7d+502vQCQggh6in5nz59mujoaIxGI1qtlnbt\n2vHbb7/Vx66FEEJUol6afZo2bcrixYvJzs7GYDCwa9cuWrVqdcV2q1evZvXq1QDMnDkTs9ls97qq\nqmRkZNgW57iac+fOISNYrSorC51OR2BgoFNm1nQ2nU53xe/KnUl5lHO3sqi3cf5r165lxYoVmEwm\nmjRpgl6vZ9y4cVW+5/IO3/z8fPR6/TXXmdXpdNesINxFZWVRUlJCcXGxW06Q5QqderVJyqOcK5RF\ng+zwHTBgAAMGDADg888/JygoqNqfYbFYqr3AuLiSTqeT9U+FcHP1Ns4/KysLgLS0NLZu3erQSkWX\nc8dmiroiZSmEe6u3w+g5c+aQnZ2NTqdj4sSJV6z6UxtUiwWys7B4eIJBFncWQoirqbfk//LLL9f9\nThQFLl7AUlwE5utfk1QIIVyVS03voCgKeHij5uVYzwJqWVZWVpVrul7N2LFjbc1e1fHnP//5ipWP\nhBCiNrhU8gfA0wssFijIr/WPvnjxIp9++ukVz19rZNHChQvx8/Or9XiEEKKmGu3QGcviD1FPJlXy\nigqFBaDRgv7KJe6qojRtieb+R676+owZM0hOTmbw4MHo9XqMRiN+fn4kJiayceNGJkyYQEpKCoWF\nhUycOJExY8YAEB8fz/Lly8nNzWXMmDHccMMNbN++nbCwMD755BOHhlxu2LCBV155hdLSUjp37sxr\nr72G0WhkxowZrFy5Ep1Ox0033cTf//53fvjhB+bOnYtGo8HPz4+vv/66WuUghHB9jTb5X51iTfyW\n0lr/5BdffJHDhw+zatUqNm/ezIMPPsjatWtp1qwZYO3UDggIID8/n2HDhjF06FACAwPtPiMpKYn3\n3nuPWbNmMWnSJJYtW8bdd99d5X4LCgp4+umnWbJkCa1atWLy5Ml8+umn3H333Sxfvpz169ejKIqt\naemtt95i0aJFhIeHk5ubW+vlIIRo/Bpt8q/qCF1TkEfpmdMQ1gTFVHcXMnXp0sWW+AE++eQTli9f\nDlgvUEtKSroi+Tdt2pTY2FgAOnXqxMmTJ6+5n99//51mzZrZroq+9957+c9//sP48eMxGo08++yz\nDBo0iEGDBgHQvXt3nn76aUaMGFGjBcWFEK7P9dr8AcXTyzryJy+nTvfj6elp+3vz5s1s2LCBH374\ngdWrVxMbG1vphVRGY/kQVK1WS2lpzc9QdDodP/74I8OGDWP16tX84Q9/AOD111/nueeeIyUlhSFD\nhpCRkVHjfQghXFOjPfKviqLRgskT8nJRA8y1dkGTl5cXOTmVVyjZ2dn4+fnh4eFBYmIiO3furJV9\nArRq1YqTJ0+SlJREy5Yt+frrr+nZsye5ubnk5+czcOBAevToQa9evQA4fvw4Xbt2pWvXrvzyyy+k\npKRccQYihHBvLpn8Aeuon/RcKCoEo6lWPjIwMJAePXowYMAATCaT3SRQ/fr1Y+HChdx88820atWK\nrl271so+AUwmE2+++SaTJk2ydfiOHTuWzMxMJkyYQGFhIaqqMm3aNACmT59OUlISqqrSt29fOnTo\nUGuxCCFcQ4NewP3yid3y8vLsmlquRqfTUVxYACePg38Ain/15xFyFVeb5M7RsnQ1rjB5V22S8ijn\nCmVRnYndXLLNH0DR6sBkgjwZ7SKEEJdz3WYfAE9vyDiPWlyEUs0x//XpxRdfZNu2bXbPPfzww9x3\n331OikgI4epcO/l7eAHnrUf/fg03+c+YMcPZIQgh3IzLNvsAKHq9dXZPafoRQgg7Lp38AWvTT2E+\nqqzsJYQQNm6Q/MvWDciXo38hhLjE9ZO/3mC91fHVvkII0Zi4fPK3zvHvBQX5qNcxlUJNxMTEXPW1\nkydP2tY0FkKI+ubyyR+wNv2oKuTnOTsSIYRoEBrtUM+Ptp8l6UJBpa8pikLFC5dVgEILaM6g6K8+\nyVnLABMPd7/68o8zZswgIiKCcePGAdYpnLVaLZs3byYrK4uSkhKee+45brnllmp9l4KCAl544QX2\n7t2LVqtl2rRp9OnTh8OHD/PMM89QVFSEqqp88MEHhIWFMWnSJFJTU7FYLDz11FPcfvvt1dqfEEI0\n2uRfHQqgarRQWoqqtz6uiZEjRzJt2jRb8v/hhx9YtGgREydOxMfHh4yMDEaMGMGQIUOqNZncggUL\nUBSFNWvWkJiYyAMPPMCGDRtYuHAhEydO5K677qKoqIjS0lLWrl1LWFgYCxcuBKyriwkhRHU12uRf\n1RF6ZfPZqPl5cPY0hASheHrXaJ+xsbGkpaVx5swZ0tPT8fPzIyQkhH/84x/89ttvKIrCmTNnOH/+\nPCEhIQ5/7rZt2xg/fjwA0dHRNGnShGPHjtGtWzfeeecdUlNTue2224iKiqJt27a8/PLLvPrqqwwa\nNIj4+PgafRchhHtzjzZ/sM7zo9Fe9wVfw4cP58cff+R///sfI0eO5JtvviE9PZ3ly5ezatUqzGZz\npfP418Sdd97J/PnzMZlMjB07lo0bN9KqVSt++ukn2rZtyxtvvMHcuXNrZV9CCPfiNslfUTTg4Qn5\nuVzPRKYjR47k+++/58cff2T48OFkZ2djNpvR6/Vs2rSJU6dOVfszb7jhBr799lvAumrX6dOnadWq\nFcnJyTRv3pyJEydyyy23cPDgQc6cOYOHhwd33303f/zjH0lISKjxdxFCuK9G2+xTI57ekJsNBfnW\niqAG2rRpQ25uLmFhYYSGhnLXXXfx0EMPMXDgQDp16kR0dHS1P/Ohhx7ihRdeYODAgWi1WubOnYvR\naOSHH37g66+/RqfTERISwp/+9Cf27NnD9OnTURQFvV7Pa6+9VqPvIYRwby47n39lc9irFgucTAJv\nX5Sg4FqLsyGT+fztucKc7bVJyqOcK5SFzOd/FYpGAx4e1930I4QQjZ17NfuAtekn72ytLu9YlYMH\nDzJ58mS754xGI0uXLq3zfQshxNU0quRfK0frHl6gKNZRP/WQ/Nu1a8eqVavqfD/VJWc+Qri3RtXs\no9FoKm2/rg5FqwWjh1tP9FZSUoJG06j+6YUQtaxRHfmbTCYKCgooLCys8gpao9FY5Vh7S24uHD+K\nYvJE8fCqi1AbjMvLQlVVNBoNJlPdn/UIIRquRpX8FUXBw8Pjmttdq9deDQjAMnMeSlE+mtvuqc0Q\nGxxXGMEghKh9bnnurwQGQ/No1F2/OjsUIYRwCrdM/gBKXE9IOoJ6Id3ZoQghRL1z3+TftRcA6m45\n+hdCuB/3Tf7hTSEsUpp+hBBuyW2TP5Q1/RxOQM3NdnYoQghRr9w8+fcCiwV1zzZnhyKEEPXKrZM/\nzaPBP0iafoQQbqfexvkvXbqUtWvXoigKTZs25fHHH8dgMNTX7iulaDQocfGom1ajFhaiGI1OjUcI\nIepLvRz5Z2RksHz5cmbOnMmcOXOwWCxs3ry5PnZ9TUpcLygqgv07nR2KEELUm3pr9rFYLLZFyIuK\niggICKivXVctpgN4ekvTjxDCrdRLs09gYCAjRozgsccew2Aw0LlzZzp37lwfu74mRadD6dwDdc9W\n1JISFF2jmvFCCCFqpF4yXU5ODtu2beO9997D09OTN998k/Xr13PTTTfZbbd69WpWr14NwMyZMzGb\nzTXan06nq9Z7C24eQtaWn/E9exJj5x412mdDVd2ycHVSHvakPMq5W1nUS/JPSEggJCQEX19fAOLj\n4zly5MgVyX/QoEEMGjTI9rimE5JVdzIztUk0GAxk/bICTWTLGu2zoZKJ3exJediT8ijnCmXR4JZx\nNJvNHD16lMLCQlRVJSEhgcjIyPrYtUMUoxE6dEXd/at1nV8hhHBx9XLkHxMTQ8+ePZk6dSparZYW\nLVrYHeE3BEpcL2un7/GjENXG2eEIIUSdqrfezVGjRjFq1Kj62l21KZ16oGq1qLt+RZHkL4Rwce59\nhW8Fipc3tI5F3fWrrG8rhHB5kvwrUOJ6wdnTkHrS2aEIIUSdkuRfgdIlHkAu+BJCuDxJ/hUoAUHQ\nsrUkfyGEy5PkfxklrhckJ6Kmn3d2KEIIUWck+V9GiesJyPKOQgjXJsn/MkpYJIQ3laYfIYRLk+Rf\nCSWuFxzZj5p90dmhCCFEnZDkXwmla09QLah7tzo7FCGEqBOS/CvTrBUEBkvTjxDCZUnyr4SiKNaO\n3/27UAvynR2OEELUOkn+V6HE9YSSYlneUQjhkhxO/tnZ2XUZR8MT3R68fVB3StOPEML1ODyr5+OP\nP07Hjh256aab6N69OzoXX+5Q0WpROt+AuvNX1JJiFJ3e2SEJIUStcfjI/7333iM2Npbvv/+eRx55\nhHnz5nHo0KG6jM3plLhekJ8LhxKcHYoQQtQqhw/ffX19GTp0KEOHDiUlJYX169fzz3/+E0VR6Nu3\nLwMGDCA4OLguY61/7buA0WSd4z+2q7OjEUKIWlOjDt/MzEwyMzPJz88nNDSUjIwMnnvuOb777rva\njs+pFL0BYrui7vlNlncUQrgUh4/8T548yYYNG9i4cSNGo5Gbb76ZWbNmERQUBMDdd9/NlClTuOOO\nO+osWGdQ4nqh7tgMxw5DdDtnhyOEELXC4eQ/bdo0+vTpwzPPPEN0dPQVr4eEhDB06NBaDa4hUDp2\nR9XqrE0/kvyFEC7C4eT/wQcfXHOEz3333XfdATU0iqcXtO2IumsL6j3jUBTF2SEJIcR1c7jN/9NP\nP+Xw4cN2zx0+fJgFCxbUdkwNjhLXC86fgdPJzg5FCCFqhcPJf9OmTbRq1cruuaioKDZu3FjrQTU0\nSpd4UBSZ60cI4TIcTv6KomC5bMSLxWJBVdVaD6qhUfwCIKoN6q4tzg5FCCFqhcPJv23btixevNhW\nAVgsFr788kvatm1bZ8E1JEpcLziZhHr+jLNDEUKI6+Zwh+/48eOZOXMmkyZNwmw2k5aWRkBAAFOn\nTq3L+BoMJa4n6lfzUXf/hjL4dmeHI4QQ18Xh5B8UFMTrr79OYmIi6enpBAUFER0djUbjHhODKiHh\nENnc2vQjyV8I0chVa3Y2jUZD69at6yqWBk+J64X64xLUi5kovv7ODkcIIWrM4eSfl5fHl19+yYED\nB8jOzrbr6P33v/9dJ8E1NEpcT9Sli1H3bEXpO8TZ4QghRI053Gbz0UcfkZSUxD333ENOTg4TJkzA\nbDYzbNiwuoyvYWnaEoJCZMinEKLRczj57927l2effZYePXqg0Wjo0aMHTz/9NBs2bKjL+BoU6/KO\nveDgbtT8PGeHI4QQNeZw8ldVFU9PTwBMJhN5eXn4+/tz5ox7DX20Lu9Ygrpvh7NDEUKIGnO4zb95\n8+YcOHCAjh070rZtWz766CNMJhPh4eF1GV/DE90WfPxg16/Qo6+zoxFCiBpx+Mh/0qRJtsVaxo8f\nj8FgIDc3lyeffLLOgmuIFI0WpUs8asJ21OJiZ4cjhBA14tCRv8Vi4ZdffuGuu+4CwM/Pjz/+8Y91\nGlhDpsT1RN2wEg7tgY7dnR2OEEJUm0NH/hqNhpUrV6LVaus6nsahbWcwecioHyFEo+Vws89NN93E\nqlWr6jKWRkPR662LvOz+DdVS6uxwhBCi2hzu8E1MTOSnn37if//7H0FBQXaLmrz00kt1ElyDFtcT\ntm2AxEPQuoOzoxFCiGpxOPkPHDiQgQMH1mUsjYoS2w1VV7a8oyR/IUQj43Dy79evX413kpKSwty5\nc22Pz507x6hRoxr11cGKhye062Jd3nHUBFneUQjRqDic/NeuXXvV1wYMGFDleyMiIpg1axZgHTk0\nadIkbrjhBkd33WApcT1RE7bDySRoFuXscIQQwmEOJ//Lp3HIzMzkzJkztG3b9prJv6KEhATCwsJs\n1ww0ZkrnG1AVjbXpR5K/EKIRcTj5T5s27Yrn1q5dy+nTp6u1w02bNtGnT59qvaehUnz9IbqtdY7/\n20c7OxwhhHBYtebzv1y/fv2YOHEiY8eOdWj7kpISduzYwejRlSfK1atXs3r1agBmzpyJ2WyuUVw6\nna7G762u3BsHkTP/HfyLC9CFN6mXfVZHfZZFYyDlYU/Ko5y7lYXDyf/yxduLiopYv349Xl5eDu9s\n165dtGzZEn//yhdCGTRoEIMGDbI9TktLc/izK7q0zGR9UFt3BCBj7XI0t9xZL/usjvosi8ZAysOe\nlEc5VyiLiIgIh7d1OPk/8MADVzwXGBjIpEmTHN6ZKzX5XKKYQ6FpS2vTTwNM/kIIURmHk/+7775r\n99hoNOLr6+vwjgoKCti7dy+PPvqo49E1EkpcL9QfvkDNuoDiF+DscIQQ4pocnt5Bq9Xi4eFBcHAw\nwcHB+Pr6kpOTQ0ZGhkPvN5lMfPLJJ7Y1AVyJEtcTVBV192/ODkUIIRzicPKfNWvWFYk+IyOD2bNn\n13pQjU5kcwgOszb9CCFEI+Bw8k9JSaFZs2Z2zzVr1qzaQz1dkW15x0MJqHm5zg5HCCGuyeHk7+vr\ne8WSjWfOnMHHx6fWg2qMlLieUFpiveJXCCEaOIeTf//+/ZkzZw47duzg1KlTbN++nTlz5lTr6l6X\nFtUG/AKk6UcI0Sg4PNrnjju1xacWAAAgAElEQVTuQKfTsXDhQtLT0zGbzfTv35/hw4fXZXyNhqLR\noHSOR/3tF9SiQhSD0dkhCSHEVTmc/DUaDSNHjmTkyJF1GU+jpsT1RF3/ExzcA50b/8R1QgjX5XCz\nz3fffUdiYqLdc4mJiXz//fe1HlSj1bYjeHhJ048QosFzOPkvW7aMJk3s565p0qQJy5Ytq/WgGitF\nV7a8456tqKWyvKMQouFyOPmXlJSg09m3Eul0OoqKimo9qMZM6doTcrIh8YCzQxFCiKtyOPlHRUWx\nYsUKu+dWrlxJVJTMY2+nQ1fQ6VF3/ersSIQQ4qoc7vB96KGHmD59OuvXryc0NJSzZ8+SmZnJ//3f\n/9VlfI2OYvKADnGou35Fve9hWd5RCNEgOZz8mzZtyttvv82OHTtIT08nPj6ebt26YTKZ6jK+RkmJ\n64m6Zysc2gvtOjs7HCGEuILDzT5gnZytT58+jBw5kj59+nD+/Hk+++yzuoqtRtLziikqsVx7wzqk\ndOkJgWYsb7+EZeW3qBbnxiOEEJer9kpeFy9eZOPGjaxbt47jx48TFxdXF3HVSHZhKU8vP86gNnk8\nGOvntDgUL280//cWlk/fRf1yPur+XWjGP4XiH+S0mIQQoiKHkv+l5RfXrVvH7t27CQoK4sKFC7z2\n2msNqsPXx6ilf0s/vt6TSktvhb4tHF9voLYp3r5oHnsBdcMK1CUfYXlpMpqH/mQ9KxBCCCe7ZvL/\n6KOP2LJlC1qtlp49e/KPf/yD1q1b8+ijjxIU1PCOZMd2CeZYZgnv/naGloFGmvg6b5oFRVFQbroV\nNSYWy0dzsLw3A+WmW1FGTUQxyvQPQgjnuWab/6pVqwC49957uf/++2ndunWdB3U9dBqFl25rg0Gr\n8Mb6FAqd3P4PoIQ3QfPCGyi33Im6/ics059GPfG7s8MSQrgx7T/+8Y9/VLXBzTffjMFgYOXKlfz3\nv/8lKSkJjUbDzp07GTJkSJ2O9snOzq7R+4IDfAkzWvj+UAbp+SX0bOr8aacVjRalfRxKTHvUbRtQ\n1ywFgwFatqnT4aCenp7k5eXV2ec3NlIe9qQ8yrlCWVRniv1rJn8vLy/at2/P0KFDad++PampqXz3\n3Xfk5uaSk5NDWFhYtdbyrY6aJn9PT098tSWoqPxw+ALBXjqiAhvGkFQlOAyl9wDUM6dgzVLUY4dQ\n2nVCMdXN8pau8IOuTVIe9qQ8yrlCWVQn+SuqqqrV3UFRURFbt25l3bp17Nu3jy+++KK6H+GQlJSU\nGr3PbDaTlpZGqUXlpZ9PcvB8Pm/c0pyWAQ2jAgBQVdXWGYzBWGedwZfKQlhJediT8ijnCmURERHh\n8LbXTP6LFy8mLi6O1q1bV9o8kZGRQWBgYPWjdMD1Jn+AzIISnl52HJNOYc5tLfDUa2szxOumpp7C\n8tEcOPF7nXQGu8IPujZJediT8ijnCmVRneR/zQ5fk8nEokWLePTRR3nnnXfYsGGDXXNMXSX+2uJv\n0jHlxgjO5BTzz1/PUIMTnTolncFCCGe4Zpt/27Zt6d+/PwMHDkSr1bJ7924WLlzIr7/+SmZmJiaT\niYCAgDoJ7nra/Cu23QV76TFoFZYevoC3QUsbs0dthVgr6rIz2BXaMWuTlIc9KY9yrlAWdd7mr6oq\niYmJ7Nq1i127dnHhwgUefPBBevfuXd2PqlJtNPtcoqoqM9afZmdKDjMGN29wFcAlas5FLP95F3b/\nCu06o5nw5+u6MtgVTmVrk5SHPSmPcq5QFrXa5u+IrKws8vLyCA8Pv96PslObyR8gp2z6B4uqMndo\nS3yNDav9/5La7Ax2hR90bZLysCflUc4VyqJW2/wvWbp0KcePHwfgyJEjPPbYYzzxxBMcOXIEPz+/\nWk/8dcHbqGVq30gyC0p5a3MKlgbW/n+JoihobroVzd/egsAQLO/NwLLwX6iFhc4OTQjhIhxO/j/+\n+CMhISEAfPHFFwwfPpy7776bBQsW1FVsdSI6yMTD3ULYkZLL1/vTnR1OlaQzWAhRVxxO/nl5eXh6\nepKfn8/x48e57bbbGDBgQI2bZpzp1hh/bmruy+d709h7JtfZ4VRJ0enR3DMezTOvQEEelhlTZJpo\nIcR1czj5BwUFcfjwYTZt2kS7du3QaDTk5eWh0VRrSYAGQVEUHo8PI8LHwJxNKWTklzg7pGtS2nVG\nM+0d6Ngd9cv5WN6ahprZsM9chBANl8OZe8yYMbz55pt8++233HPPPQDs3LmT6OjoOguuLnnoNUzt\nG0l+sYU5G09TammY7f8VKd6+aB5/AWXs4/D7QSwvTUbdLWsFCyGq77pG+5SUWI+YdbpqrwnjkNoe\n7VOZn49l8daWVO7pEMTYLsE12p8zWK8Mng0njlV5ZbArjGCoTVIe9qQ8yrlCWdTJaJ9Tp06RmZkJ\nQEFBAf/973/59ttvKS0trX6EDUj/KD+GRPvx1f50tp/OcXY4DlPCm6B5flaFzuA/S2ewEMJhDif/\nt99+23b126effsrBgwc5evQoH3zwQZ0FV18e6R5KywAjczencC6n2NnhOEzRV+wMzrd2Bq+QzmAh\nxLU5nPzPnTtHREQEqqqydetWnn76aZ555hn27NlTl/HVC4PW2v5vUeGNjacpLm347f8V2XUGfyWd\nwUKIa3M4+RsMBvLz80lMTMRsNuPr64ter6e4uPEcKVcl3MfA5J7hHE0vYMGuc84Op9qkM1gIUR0O\n99T26dOHl19+mfz8fG699VYAkpKSbBd+uYJezXwY2TaA/x26QPtgD/o0d94C8DVhv2bwbCzvzeDi\n4QTUm4eihEU6OzwhRANSrdE+e/bsQavVEhsbC8Dvv/9Ofn6+7XFtq4/RPpcrsai8uOoEJzILmXNb\nCyJ9DTX6HGdTi4tRv/sMddV3oKrQrBXKDTeh9LgRJbDxjGqqba4woqM2SXmUc4WyqNOJ3dLS0mwL\nuJjN5moHVx3OSP4A53OLeXr5cYI8dLxxS3OMusZ3IdslAVhIX/k/1G0b4PhR65PR7a0VQbfeKL7+\nzg2wnrnCf/DaJOVRzhXKok6S/4ULF3jrrbc4evQo3t7eZGdn07p1a5566qkGvZJXTe1MyeHln08x\nsJUff+rZ8Cetu5qKZaGeS0HdugF163pIPQkaDbTtbK0I4uJRPL2dHG3dc4X/4LVJyqOcK5RFnST/\nN954A7PZzOjRozGZTBQUFPDFF19w7tw5pk6des335+bm8v7773Py5EkUReGxxx6jdevWVb7Hmckf\nYNGe8/x3XzqTe4YxsFXjPEK+Wlmop46jbl1vPSNIOws6HcR2t1YEnXrU6lKSDYkr/AevTVIe5Vyh\nLKqT/B3u8D18+DDPPPOM7Wpek8nEmDFj+OMf/+jQ++fPn0+XLl149tlnKSkpobARTE98f0czh87n\n8/62s7QKNNGiAS0Af72UJi1QmrRAvXMsJB2xVgTbN6Hu/hXVaELpHI9yQ1/oEIei0zs7XCFELXO4\nMdvLy4tTp07ZPZeSkoKnp+c135uXl8fBgwcZMGAAYJ0OwsvLq5qh1j+tRuHZPhF4GbS8viGFvOLG\nfTVzZRRFQYlqg+b+R9C88TGaZ6ejxN+Mun8nlnenY3n2ISyfvot6cA+qxfW+vxDuyuFmn9WrV/PF\nF18wYMAAgoODOX/+PL/88gv33XcfgwYNqvK9x48fZ968eTRp0oTk5GSioqIYN24cJpP9kfTq1atZ\nvXo1ADNnzqSoqKhGX0qn09nmHaoNu09nMfnrBG6ONvPybde/rm59qmlZqMXFFO3ZSsHG1RT+tgG1\nIA9NQBDG3gMw3TgIfZvYRlUOl9T2b6Oxk/Io5wplYTA4PjqxWqN99u3bx8aNG7lw4QIBAQH06dOH\nAwcOcN9991X5vt9//52//vWvvPLKK8TExDB//nw8PDy4//77q3yfs9v8K/p6fzqf7j7Po91DGdam\nbhasrwu1URZqYSEkbMOybQPs3Q4lxRAUgnJDX5QeN0GTFo2mInCFdt3aJOVRzhXKok7a/AFiY2Pt\nxvQXFxczffr0ayb/oKAggoKCiImJAaBnz55899131dm1093ZPpCD5/P4ZOdZYoJMtG6gC8DXBcVo\nhO43ou1+I2perrVfYNsG1BXfoi7/GsKb2ioCJdTxH58QwnnqZQC7v78/QUFBtiP5hIQEmjRpUh+7\nrjUaReGpXhEEeuiYtfE02YXu2f6teHqh6T0Q7VP/QDP7Pyh/eAx8fFG//xzL3/5I6fRnrJPLZZx3\ndqhCiCrUzUT8lZgwYQLvvPMOJSUlhISE8Pjjj9fXrmuNj1HLc30jeX7lCd7anMJf+zVB00iaO+qC\n4uOH0u826HcbakYa6vYN1usIvpqP+tV8iLl0MVkfFB8/Z4crhKjgmsl/3759V32tOp0jLVq0YObM\nmQ5v31DFBHkwoWsIH2w/yzcHMrinQ5CzQ2oQlEAzypA7YcidqGdTrM1CW9ejLnof9YsPoE1HlDYd\nUWI6QMsYFH3jnDZDCFdxzeT/73//u8rX63qKh4ZoaGt/Dp7PY9Ge87Q1exAbeu3hru5ECY1AGX4f\n6rBRcPq49Wxg7zbrXEMAOj1EtUaJ6YDSugNEtUUxuU8fihANwXUt41jXGtJon8vlFZfyl5+SySsq\nZe7QlgR41FsLWrU0pBEMas5FSDyIenQ/6pH9cOJ3sFis00w0a4XSuoP1zCCmPYqXT53E0JDKoyGQ\n8ijnCmVRZ6N9RDlPvZapfSP5y0/HmbMphZcGNEWrcd/2f0co3r7QJR6lSzwAakEe/H4Y9ch+1MT9\nqGt/RF1ZNgossrn1rCAmFiWmPYp/3cwfJYS7kuR/HZr7G3nshjDe3pLKF3vTGNOIFoBvCBSTp3X6\niA5xAKjFRZB01HZmoG5eCz8vszYVhUSUVQbtrWcH5tBGc22BEA2RJP/rNCDKj/3n8vhyfzrtgj3o\nFun6M2PWFUVvgNZl/QDDQC0thRPHUI/us1YGO7fAxlXWyiDAbK0ELm0f1kQqAyGqQZJ/LXi0eyi/\nZxQwd3MKc4e2JNhLJkKrDYpWax0Z1DLGOorIYoGUE6hHD8DR/aiH98LWddbKwMfPdlagtO5gvepY\no3X2VxCiwZLkXwuMOg3P3RjJM8uP88aG08wY3By9Vo5Ca5ui0ViTepMW0H8oqqrC+VRr5/GR/dbm\nop1brJWBhye0alfeidwiWmYnFaICSf61JMLXwJ96hfHGhhT+s/scD3cLdXZILk9RFGtfQEgE3DgY\nADXjvPXM4FJl8M0Oa2VgMEDLNmTHxmEJCLZWIKERUiEItyXJvxb1aebL8Db5/FC2AHzvZo1rAXhX\noAQGo8TfDPE3A6BmZ8HRA2WdyPvI+24RlJZaKwStDsIiUSKbQ0Qza4UQ0cw6aZ2m8S7dKYQjJPnX\nsnFxIRxJy+efv57Bx6ilY2jDX7fAlSk+ftC1F0rXXgAE+fmStn8v6ulkOJ2MejoZ9fdDsHU9tgte\njB4Q0dRWGSiRza1DT91svWPh2iT51zK9VuG5vpG8uOoEf1t9kp5NvRkXF0K4j0xn0BAoeoNtFbOK\n1Pw8a2dyxUph16+wYWV5peDjZ60ELlUGl84Y5Opk0QhJ8q8DwV563h3ekv8dyuCr/Rk8efoYw9sE\ncm9sEN4GGYHSECkentCqLUqrtrbnVFWF7Ew4lYyaklx2fwJ1w0ooKiyvFMyh9pWB9CeIRkCSfx0x\n6jTcG2tmUCt/Pttznu8PZrDmWBYPdDRza4y/XA3cCCiKAr4B0D4ApX0X2/OqxQLp56zzFp0+UX6m\nsG+H9CeIRkPm9qknSRcK+GTHOfaezaOJr4HxXUPoFuFV5xcmNcSycKa6LA+1uBjOnrZrOuJ0srWi\nuORSf0JYEwgJh+Aw62ilkHAUr/q/QFB+H+VcoSxkbp8GqGWAiZcHNmXr6RwW7DzHK7+coku4FxO6\nhtDc3+js8EQtUPT68usQKrDrT0g5gXrqOOrBPbBlrfX1Sxt6elsrgeAwa8UQEo4SbL3H11+uYBa1\nSpJ/PVIUhfgmPnQN92b50QssTkjjz8uSGNzKn9Gdzfib5J/DFVXWnwCgFhXC+bNwPgX13BnrBWvn\nUlGPH4Xtm0C1VBiBZIKySkGx3ZdVDAFBcjWzqDbJNk6g1yqMbBtIv5Z+LElIY/mRC2xIvsi9HYIY\n0TYAvVbahN2BYjBCZDOIbMblx/RqSQlknINz1gqB82es9yknUfdug5KS8opBp7N2OgeHo4SEl9+H\nhENQsHQ8i0pJ8nciX6OWR7qHcltrfxbsPM9/dp/np8RMHooLpndTHznNd2OKTgchEdYrmC97TbWU\nwoUM25kC51JRz5+x3h/ZD4X55RWDooGg4LK+hcuaksxh9fytREMiHb4NyO7UXObvPMfxzELaB3sw\noVsIMUHXN4a8sZZFXXH18rANTz2XamtKqlg5kJttt70mKBhLUGh5xVB25kBImHXKbTfiCr+N6nT4\nSvJvYEotKmuOZfHZnvNkFZTSr6UvY7sEY/as2al7Yy6LuuDu5aHm5tidMRizL1Bw4ri1ksi6YL+x\nr7/9mUJIeXOS4ul6U5e7wm9DRvs0YlqNwpBof25s7sPX+zP4/mAGm09kc2f7QO5qH4RJJ/0BouYU\nL2/wikFpEQOAn9lMcVnCUwvy4VLz0bnU8g7oQ3uvHJnk7WPft2CrJCLAW5osGwNJ/g2Up17L2C7B\nDIn249Pd51mSkM7KxCzGdjbTP8oPjfznErVMMXlA05bQtOWV/Qx2I5NSbRWEmngQtq4HVS2vGDy8\nLmtCqlBJyJDVBkOSfwMX6m1gyo2RjGiTz8c7zvLOr2f48cgFJnQNJTbUvdpkhfNUOTKpuBjSz8LZ\nVNTzKeUVw/GjsGMTWC4fsnpZE5I5FPwCwNvXetYgw1brhST/RqJtsAev39KcDccv8unu8/x19QmZ\nNE40CIpeD2FNrEtpXvbaFUNWL92nJKPu2QqlFYasAiiK9WI3H9+yysAPxcdaKeDtB96+1plavX3L\ntzGa5GyiBiT5NyIaReHmln70bOrD9wcz+PpAukwaJxq0aw5ZzUizXsOQnQU5F623bOu9mp1l7XdI\nOmx9vrTU+r7Ld6I32FUGirdfhcqjksrCy8e6RKibk+TfCBl1GkZ1NDMo2p9FMmmcaKQUjdZ6cZo5\n9IqK4XKqqkJ+7pWVQyWP1fNnrM/n51nfe8WOy84uKlYYPn5kh4Rh0enBx9+6doNvAPj6WSsLF5yM\nT4Z6uoBjGQV8vPMc+8omjZvQNYRukdaheO5WFtci5WHPlctDLS6G3AqVQ85FuEqFYbuVnV3Y0Wis\nazn4+Fs7rH39rMNgff3LKooKj739rGc7TiJDPd1MVKCJ6QObsvVUDvN3nePlX04RF+7F+K4hmM3O\njk4I51D0evAPst7gmmcXQYGBpJ04DhczITsL9WKm9e/LHqtnT1ufKy4CKjmz8PapUFFcqiT87B+X\n3RS98/rrJPm7CEVRiG/qQ9cIb5YducCSfdZJ44a1z6NbqIG2Zg889K536ipEbVE0GpSyfgKourJQ\nVRUK88srh4uZqBezyiqKzLKKIgs1+XfrFddXa4Ly8LRVDLbKwT8IzbBRdfIdK5Lk72L0WoXb2wXS\nP8qPxQlpLD94jh/2q2gViA7yoGOoJx1DPWkb7CEXjAlRQ4qigMnTeguxNrVUWVkUFVqbnMoqCPXi\nBdsZhfVxJqSeQj2yz7rmQz0kf2nzd3GevgFsOnyKfWfzSDibR2J6PqUqaBWICfIg1s0qA/lt2JPy\nKNdQykK1lNb4Wgdp8xc2ngYtceFexIV7AZBfbOFQWr6tMvj2QDpf7U9328pAiIamvi5yk+TvZjz0\nmisqg4Pn89h3No995/L4RioDIdyCJH8356HX0DXCm64R1qGhV6sMdJqyyiDEk9hQT9oFe2CUykCI\nRkuSv7BzeWWQV1zKofP5tsrg6wPpfCmVgRCNniR/USVPvbbSyiDhrPXsoGJl0LqsmSg21JO2ZqkM\nhGjIJPmLarlWZfDV/nT+u08qAyEaOkn+4ro4WhkoQKi3nia+Bpr4GWnqZyDS10BTXyPeRplkS4j6\nVm/J/4knnsBkMqHRaNBqtcycObO+di3q0dUqgyNpBZy8WMiprCL2nMmj2FJ+eYm/SWutEHwNNPEz\n0MTXSBM/A0EeOpmqV4g6Uq9H/tOmTcPX17c+dymc7PLKAKzrFJ/LLeZUVhEnLxZy+mIRJ7OKWJ98\nkdwii207D52mrDKwni00Kascwr0NMnOpENdJmn1EvdNqFMJ9DIT7GOhBeaWgqiqZBaWczCrk1MUi\n6y2rkL1n8vg56aJtO50Gwn2sZwi25iM/I5G+BrkWQQgH1dv0Dk888QTe3tb/6IMHD2bQoEFXbLN6\n9WpWr14NwMyZMykqKqrRvnQ6HSUlJTUP1oW4SlnkFpaQfCGf4xl5JF/IJzkjj+MZ+aRkWaeruCTM\nx0iLQE+aB3rQPMB63yLQE38PPeA65VFbpDzKuUJZGAyOzxJab8k/IyODwMBAsrKymD59OuPHj6d9\n+/ZVvkfm9rl+rl4WxaUWUrOLrc1HWUWcLDtbOHWxiKIKtYKvUUsTXwNRIb74aUsJ8dYT4qUnxFtP\noIcOjZv2Lbj676M6XKEsGuTcPoGBgQD4+fnRo0cPEhMTr5n8hbgWvVZDM38jzfyNds9bVJXzZf0K\n1iYka2fzlqQM0vOK7bbVaSDYq6wyKKsQQrz0hJb9HeDGlYNwXfWS/AsKClBVFQ8PDwoKCti7dy/3\n3HNPfexauCmNohDqbSDU20C3yPLnzWYzp8+c43xeMedyijmbU8y53LJbTjHbTueQWWC/mpNOoxDi\npbOrGCr+LZWDaIzqJflnZWUxe/ZsAEpLS7nxxhvp0qVLfexaiCsYdRrrcFJfY6WvF5ZYOJ9rXzFc\n+vu3UzlkXVY56DWK9czBu+xsoWIl4a3H36SVykE0OPWS/ENDQ5k1a1Z97EqI62bUaaxDS/0qrxwK\nSiy2MwW7+9xifs0oIKvQvnIwaJUrmpX8TVq8DFq89BrbvWfZvQxjFfVBhnoKUU0mnYZmfkaaVVU5\n5NifMVyqJH7PKOBiYSWLhF/2+dZKwVoxeFaoICree1bYxsugwUtvvTdoZbiruDZJ/kLUMpOu8k7o\nS/KLLVwsLCG3yEJucSl5RRZyiy3kFpWW3xdZyCu23mcWlHD6YpHtNcs1xufpNQqeFSoDW6Vh0OCp\nt68omuZqUQoL8DVp8TNq0UvF4TYk+QtRzzz0Gjz0jo/HrkhVVQpLVVsFkVtWQeQWlZJXbLF/rri8\nEknLK7FVLhWHwEKq3ed76TX4mbT4mXTWe2PZfYW//cte8zZopYmqEZPkL0QjoigKJp2CSachyLNm\nn1FceulMw4LG5E3y2XSyCkrJKighs7CUiwUlZBWUknqxmIOF+WQXVn62oVHAx6C1ryxMOvyN1ntf\nk9b2t5/J2kwlczU1HJL8hXAzeq0Gf60GfxOYzb6EG6q+kr7UopJTVGqtIApLyiqKUjLLKomswhIu\nFpRyLKOQrMJcu/mZKtJplLIzBy2+Fc4ifIxaTDoFg1aDQauU3TSX3SvotQpGrQaDTkGv0aDTIJXJ\ndZDkL4SoklajlB2964DK+zEqKi5VuXipkii0nlHYVRYFJWQVlnL6YhGZBSWXNUM5TqNY+zcMusoq\nDQW9VoPxsr/12qtVMgrmTCjKz8WkVTDqNHjoNRh1Gkw6a6Xjak1ckvyFELVKr1UI8tQT5Kl3aPvC\nEguFJRaKLCpFJSpFpdZ+Cevtyr+LS1UKSy0Ulz1fWGKh+NJ7LRbbZ+QVlZJ5lc+pvNM8tbInbQxl\nlcIVlUMlj006DSa9BpPOWulU9digVZxyHYgkfyGEUxl1mnpf5a3UYq1AKlYmnj5+nD2fQX6JhcIS\nlYISi+12+eOCEmulU1BiIaOotPxxqYWCYgvVPZkxahVbZRDkoeO1Ic3r5otXIMlfCOF2tBoFT42W\niicnZrM3gUpBrXx+cal9ZVCxsri8AskvO/O59FivrZ+zAEn+QghRy/RaBb1WizcNd4lSuaJDCCHc\nkCR/IYRwQ5L8hRDCDUnyF0IINyTJXwgh3JAkfyGEcEOS/IUQwg1J8hdCCDekqKpas1mVhBBCNFou\neeT//PPPOzuEBkPKwp6Uhz0pj3LuVhYumfyFEEJUTZK/EEK4IZdM/oMGDXJ2CA2GlIU9KQ97Uh7l\n3K0spMNXCCHckEse+QshhKiaJH8hhHBDLrWYy+7du5k/fz4Wi4WBAwdyxx13ODskp0lLS+O9994j\nMzMTRVEYNGgQQ4cOdXZYTmWxWHj++ecJDAx0u2F9l8vNzeX999/n5MmTKIrCY489RuvWrZ0dltMs\nXbqUtWvXoigKTZs25fHHH8dgMDg7rDrlMsnfYrHw8ccf87e//Y2goCBeeOEFunfvTpMmTZwdmlNo\ntVrGjh1LVFQU+fn5PP/883Tq1MltywNg2bJlREZGkp+f7+xQnG7+/Pl06dKFZ599lpKSEgoLC50d\nktNkZGSwfPly5s6di8Fg4M0332Tz5s3069fP2aHVKZdp9klMTCQsLIzQ0FB0Oh29e/dm27Ztzg7L\naQICAoiKigLAw8ODyMhIMjIynByV86Snp7Nz504GDhzo7FCcLi8vj4MHDzJgwAAAdDodXl5eTo7K\nuSwWC0VFRZSWllJUVERAQICzQ6pzLnPkn5GRQVBQkO1xUFAQR48edWJEDce5c+dISkoiOjra2aE4\nzYIFCxgzZowc9WP9Pfj6+vKvf/2L5ORkoqKiGDduHCaTydmhOUVgYCAjRozgsccew2Aw0LlzZzp3\n7uzssOqcyxz5i8oVFBQwZ84cxo0bh6enp7PDcYodO3bg5+dnOxNyd6WlpSQlJTFkyBDeeOMNjEYj\n3333nbPDcpqcnBy2bdvGe++9x7x58ygoKGD9+vXODqvOuUzyDwwMJD093fY4PT2dwMBAJ0bkfCUl\nJcyZM4e+ffsSHx/v7NbffogAAAT8SURBVHCc5vDhw2zfvp0nnniCt956i3379vHOO+84OyynCQoK\nIigoiJiYGAB69uxJUlKSk6NynoSEBEJCQvD19UWn0xEfH8+RI0ecHVadc5lmn1atWpGamsq5c+cI\nDAxk8+bNTJ482dlhOY2qqrz//vtERkYyfPhwZ4fjVKNHj2b06NEA7N+/nx9++MGtfxv+/v4EBQWR\nkpJCREQECQkJbj0QwGw2c/ToUQoLCzEYDCQkJNCqVStnh1XnXCb5a7VaJkyYwKuvvorFYqF///40\nbdrU2WE5zeHDh1m/fj3NmjVjypQpADzwwAN07drVyZGJhmDChAm88847lJSUEBISwuOPP+7skJwm\nJiaGnj17MnXqVLRaLS1atHCLqR5kegchhHBDLtPmL4QQwnGS/IUQwg1J8hdCCDckyV8IIdyQJH8h\nhHBDkvyFqAWjRo3izJkzzg5DCIe5zDh/IS554oknyMzMRKMpP7bp168fEydOdGJUlVuxYgXp6emM\nHj2aadOmMWHCBJo3b+7ssIQbkOQvXNLUqVPp1KmTs8O4pmPHjtG1a1csFgunT5926yttRf2S5C/c\nyi+//MKaNWto0aIF69evJyAggIkTJ9KxY0fAOjvshx9+yKFDh/D29ub222+3Xe1psVj47rvv+Pnn\nn8nKyiI8PJwpU6ZgNpsB2Lt3LzNmzODixYvceOONTJw4EUVRqozn2LFj3HPPPaSkpBAcHIxWq63b\nAhCijCR/4XaOHj1KfHw8H3/8MVu3bmX27Nm89957eHt78/bbb9O0aVPmzZtHSkoKr7zyCmFhYcTG\nxrJ06VI2bdrECy+8QHh4OMnJyRiNRtvn7ty5k9dee438/HymTp1K9+7d6dKlyxX7Ly4u5pFHHkFV\nVQoKCpgyZQolJSVYLBbGjRvHyJEjueuuu+qzSIQbkuQvXNKsWbPsjqLHjBljO4L38/Nj2LBhKIpC\n7969+eGHH9i5cyft27fn0KFDPP/88xgMBlq0aMHAgQNZt24dsbGxrFmzhjFjxhAREQFAixYt7PZ5\nxx134OXlhZeXFx06dOD48eOVJn+9Xs+CBQtYs2YNJ0+eZNy4cUyfPp3777/frddcEPVLkr9wSVOm\nTLlqm39gYKBdc0xwcDAZGRlcuHABb29vPDw8bK+ZzWZ+//13wDpNeGho6FX36e/vb/vbaDRSUFBQ\n6XZvvfUWu3fvprCwEL1ez88//0xBQQGJiYmEh4fz2muvVeu7ClETkvyF28nIyEBVVVsFkJaWRvfu\n3QkICCAnJ4f8/HxbBZCWlmZbFyIoKIizZ8/SrFmz69r/n//8ZywWC48++igffPABO3bsYMuWLW49\nzbSofzLOX7idrKwsli9fTklJCVu2bOH06dPExcVhNptp06YNn3/+OUVFRSQnJ/Pzzz/Tt29fAAYO\nHMiSJUtITU1FVVWSk5PJzs6uUQynT58mNDQUjUZDUlKSW8wfLxoWOfIXLun111+3G+ffqVMn27oG\nMTExpKamMnHiRPz9/XnmmWfw8fEB4KmnnuLDDz9k0qRJeHt7c++999qaj4YPH05xcTHTp08nOzub\nyMhI/vKXv9QovmPHjtGyZUvb37fffvv1fF0hqk3m8xdu5dJQz1deecXZoQjhVNLsI4QQbkiSvxBC\nuCFp9hFCCDckR/5CCOGGJPkLIYQbkuQvhBBuSJK/EEK4IUn+Qgjhhv5/APqHQyZW5eAXAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ebd9bc390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "print ('History keys: {}'.format(model_history.history.keys()))\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs), model_history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epochs), model_history.history[\"val_loss\"], label=\"val_loss\")\n",
    "#plt.plot(np.arange(0, epochs), model_history.history[\"val_regression_loss\"], label=\"val_regression_loss\")\n",
    "#plt.plot(np.arange(0, epochs), model_history.history[\"val_classification_loss\"], label=\"val_classification_loss\")\n",
    "#plt.plot(np.arange(0, epochs), model_history.history[\"classification_acc\"], label=\"classification_acc\")\n",
    "#plt.plot(np.arange(0, epochs), model_history.history[\"val_classification_acc\"], label=\"val_classification_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(\"model_training_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the saved model.\n",
    "saved_model = 'stage2_model_epoch_10.h5'\n",
    "saved_model_weights = 'stage2_model_epoch_10_weights.h5'\n",
    "json_model = 'stage2_model.json'\n",
    "infer_model = load_model(saved_model, custom_objects={'PriorProbability': PriorProbability, \n",
    "                                                      'focal_loss_fixed': focal_loss(),\n",
    "                                                      'softmax': tf.nn.softmax})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time:  0.335660457611084\n",
      "Prediction : [array([[ 0.00132885,  0.00500442,  0.00923561,  0.00168411,  0.00152308,\n",
      "         0.0281927 ,  0.03768922,  0.00109829,  0.01671968,  0.00794278,\n",
      "         0.04237921,  0.00735675,  0.01325723,  0.00127942,  0.00202719,\n",
      "         0.0043189 ,  0.01541545,  0.03759564,  0.07310645,  0.00148191,\n",
      "         0.01255135,  0.00160528,  0.02265259,  0.00101296,  0.19606674,\n",
      "         0.0010483 ,  0.09583987,  0.00161279,  0.1478058 ,  0.00077374,\n",
      "         0.00632537,  0.00155148,  0.0018924 ,  0.02991768,  0.02734585,\n",
      "         0.00109986,  0.00174966,  0.00458858,  0.00077612,  0.00806351,\n",
      "         0.0227244 ,  0.01313054,  0.00169899,  0.00131353,  0.022917  ,\n",
      "         0.01207225,  0.00094387,  0.00921401,  0.01083577,  0.00200302,\n",
      "         0.01277831,  0.00230356,  0.00177968,  0.0014187 ,  0.00241415,\n",
      "         0.00142662,  0.00100993,  0.00181272,  0.00112175,  0.0032073 ,\n",
      "         0.00095709]], dtype=float32), array([[ 0.00093067,  0.00547911,  0.01891871,  0.00078869,  0.00212013,\n",
      "         0.0338078 ,  0.04418371,  0.00178321,  0.01765363,  0.00958299,\n",
      "         0.03822985,  0.00771262,  0.01507201,  0.00110334,  0.00146337,\n",
      "         0.00233706,  0.02326893,  0.02946983,  0.05666209,  0.00133442,\n",
      "         0.01726314,  0.00085097,  0.02719766,  0.00257489,  0.19992192,\n",
      "         0.0010243 ,  0.05058502,  0.00149514,  0.15857039,  0.00176902,\n",
      "         0.0021375 ,  0.00057254,  0.00118356,  0.03074466,  0.03533099,\n",
      "         0.00169599,  0.00211861,  0.0040592 ,  0.0016372 ,  0.00720635,\n",
      "         0.0265615 ,  0.01657232,  0.00315507,  0.00164238,  0.02475641,\n",
      "         0.01446427,  0.00124423,  0.00647152,  0.01432074,  0.00176775,\n",
      "         0.01391122,  0.00108783,  0.00160303,  0.001622  ,  0.00170002,\n",
      "         0.0029091 ,  0.00091523,  0.00079863,  0.00088193,  0.00193688,\n",
      "         0.0018367 ]], dtype=float32), array([[ 0.09636222,  0.01234889,  0.12691481,  0.04138551,  0.03343284,\n",
      "         0.53779894,  0.09933204,  0.0396543 ,  0.00388642,  0.00888396]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "prediction = infer_model.predict_on_batch(np.expand_dims(X_test[0], axis=0))\n",
    "print(\"processing time: \", time.time() - start)\n",
    "print ('Prediction : {}'.format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model prediction to labels for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject label prediction: ([-1, -1, -1, -1, -1, -1, -1, -1], ('/m/04bcr3', '/m/04bcr3', 'is'), 0.3112625330686569)\n"
     ]
    }
   ],
   "source": [
    "def get_score(subject_prediction, object_prediction, relationship_prediction, disable_regress=True):\n",
    "    subject_max = float(np.amax(subject_prediction))\n",
    "    object_max = float(np.amax(object_prediction))\n",
    "    relationship_max = float(np.amax(relationship_prediction))\n",
    "    return (subject_max + object_max + relationship_max)/3.0\n",
    "\n",
    "def get_label(lb, softmax_vector):\n",
    "    a = np.asarray(softmax_vector).reshape(-1)\n",
    "    b = np.zeros_like(a)\n",
    "    b[np.argmax(a)] = 1\n",
    "    return lb.inverse_transform(b.reshape(1, -1))[0]\n",
    "\n",
    "def convert_prediction_to_label(lb_subject_object, lb_relationship_object, prediction, disable_regress=True):\n",
    "    # regress output\n",
    "    start_idx = 0\n",
    "    if disable_regress is False:\n",
    "        boxes = prediction[start_idx]\n",
    "        start_idx +=1\n",
    "\n",
    "    label_subject_probs = prediction[start_idx]\n",
    "    label_subject = get_label(lb_subject_object, prediction[start_idx])\n",
    "    label_object = get_label(lb_subject_object, prediction[start_idx + 1])\n",
    "    label_relationship = get_label(lb_relationship_object, prediction[start_idx + 2])\n",
    "    score = get_score(prediction[start_idx], prediction[start_idx + 1], prediction[start_idx + 2])\n",
    "    if disable_regress is False:\n",
    "        return (boxes.reshape(-1).tolist(), (label_subject, label_object, label_relationship), score)\n",
    "    else:\n",
    "        return ([-1]*8, (label_subject, label_object, label_relationship), score)\n",
    "\n",
    "print ('Subject label prediction: {}'.format(convert_prediction_to_label(mlb_subject_object,                                                 \n",
    "                                                                         mlb_relationship,\n",
    "                                                                         prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (32472, 600)\n",
      "processing time:  1.741603136062622\n"
     ]
    }
   ],
   "source": [
    "# Get prediction for test set to evaluate score.\n",
    "print ('X_test shape: {}'.format(X_test.shape))\n",
    "start = time.time()\n",
    "predictions = infer_model.predict(X_test)\n",
    "print(\"processing time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction[0] shape: (32472, 61), prediction[1] shape: (32472, 61), prediction[2] shape: (32472, 10)\n"
     ]
    }
   ],
   "source": [
    "print ('Prediction[0] shape: {}, prediction[1] shape: {}, prediction[2] shape: {}'.format(\n",
    "    predictions[0].shape, predictions[1].shape, predictions[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entry_for_eval(fid, predictions, lb_subject_object, lb_relationship_object, disable_regress=True):\n",
    "    boxes_labels_tuple = convert_prediction_to_label(lb_subject_object, lb_relationship_object, predictions,\n",
    "                                                    disable_regress=disable_regress)\n",
    "    return [fid, boxes_labels_tuple[1][0], boxes_labels_tuple[1][1]] + boxes_labels_tuple[0] + \\\n",
    "            [boxes_labels_tuple[1][2]] + [boxes_labels_tuple[2]]\n",
    "\n",
    "def process_test_set_predictions(test_dataset, X_test, infer_model, \n",
    "                                 lb_subject_object, lb_relationship_object,\n",
    "                                 disable_regress=True):\n",
    "    print ('X_test shape: {}'.format(X_test.shape))\n",
    "    start = time.time()\n",
    "    predictions = infer_model.predict(X_test)\n",
    "    print(\"processing time: \", time.time() - start)\n",
    "    ret_list = []\n",
    "    print ('processing entry count: {}'.format(len(test_dataset['id'])))\n",
    "    for i in range(0, len(test_dataset['id'])):\n",
    "        fid = test_dataset['id'][i]\n",
    "        if disable_regress is False:\n",
    "            eval_output = get_entry_for_eval(fid, \n",
    "                                             [predictions[0][i],\n",
    "                                              predictions[1][i].reshape(1, -1), \n",
    "                                              predictions[2][i].reshape(1, -1), \n",
    "                                              predictions[3][i].reshape(1, -1)], lb_subject_object, \n",
    "                                              lb_relationship_object)\n",
    "            ret_list.append(eval_output)\n",
    "        else:\n",
    "            eval_output = get_entry_for_eval(fid, \n",
    "                                             [predictions[0][i].reshape(1, -1), \n",
    "                                              predictions[1][i].reshape(1, -1), \n",
    "                                              predictions[2][i].reshape(1, -1)], lb_subject_object, \n",
    "                                              lb_relationship_object, disable_regress=disable_regress)\n",
    "            ret_list.append(eval_output)\n",
    "\n",
    "    return ret_list\n",
    "\n",
    "def ouput_validation_csv(validation_list, csv_file, prefix='validation', disable_regress=True):\n",
    "    csv_file_path = os.path.join(prefix, csv_file)\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf8') as f:\n",
    "        write_one_extra = False\n",
    "        writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(\n",
    "    \"ImageID,LabelName1,LabelName2,XMin1,XMax1,YMin1,YMax1,XMin2,XMax2,YMin2,YMax2,RelationshipLabel,Score\".split(','))\n",
    "        for entry in validation_list:\n",
    "            writer.writerow(entry)\n",
    "            if write_one_extra is False:\n",
    "                writer.writerow(entry)  # Hack to write twice to fix error in ooid_vrd_challenge_evaluation.py\n",
    "                write_one_extra = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (32472, 600)\n",
      "processing time:  1.7621181011199951\n",
      "processing entry count: 32472\n"
     ]
    }
   ],
   "source": [
    "disable_regress=True\n",
    "validation_list = process_test_set_predictions(model_test_dataset, X_test, infer_model, \n",
    "                                               mlb_subject_object, mlb_relationship, \n",
    "                                               disable_regress=disable_regress)\n",
    "ouput_validation_csv(validation_list, csv_file='stage2_model_epoch_10_testset_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter input csv for evalulation\n",
    "\n",
    "This is mentioned here:\n",
    "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/challenge_evaluation.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_ground_truth_csv(prefix='data/raw', train_csv_fname = 'challenge-2018-train-vrd.csv', \n",
    "                            test_csv_fname = 'validation/stage2_model_epoch_10_testset_val.csv',\n",
    "                            filtered_csv_fname = 'validation/filtered-challenge-2018-train-vrd.csv'):\n",
    "    \n",
    "    test_fid_set = set()\n",
    "    with open(test_csv_fname, mode='r', encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            test_fid_set.add(row[0])\n",
    "    \n",
    "    filtered_truth_rows = []\n",
    "    with open(os.path.join(prefix, train_csv_fname), mode='r', encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            if row[0] in test_fid_set:\n",
    "                filtered_truth_rows.append(row)\n",
    "        \n",
    "    with open(filtered_csv_fname, mode='w', newline='', encoding='utf8') as f:\n",
    "        writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for entry in filtered_truth_rows:\n",
    "            writer.writerow(entry)\n",
    "            \n",
    "    return filtered_truth_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered set size: 234509\n"
     ]
    }
   ],
   "source": [
    "training_csv = 'challenge-2018-train-vrd.csv'\n",
    "validation_csv = 'validation/stage2_model_epoch_10_testset_val.csv'\n",
    "filtered_csv_fname = 'validation/filtered-challenge-2018-train-vrd.csv'\n",
    "filtered_ground_truth_rows = filter_ground_truth_csv(prefix='data/raw', \n",
    "                                                     train_csv_fname = 'challenge-2018-train-vrd.csv', \n",
    "                                                     test_csv_fname = validation_csv,\n",
    "                                                     filtered_csv_fname = filtered_csv_fname)\n",
    "print ('Filtered set size: {}'.format(len(filtered_ground_truth_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers for mAP calculation without using IOU for now\n",
    "\n",
    "Only measure triplet detection accuracy per class and across all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_triplet_to_image_id_dict_from_csv(csv_fname):\n",
    "    ret_dict = {}\n",
    "    \n",
    "    with open(csv_fname, mode='r', encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        header_process = False\n",
    "        relationship_idx = -1\n",
    "        for row in rows:\n",
    "            if header_process is False:\n",
    "                print ('header for {}: {}'.format(csv_fname, row))\n",
    "                relationship_idx = row.index('RelationshipLabel')\n",
    "                header_process = True\n",
    "                continue\n",
    "            fid = row[0]\n",
    "            subject_class = row[1]\n",
    "            object_class = row[2]\n",
    "            relationship_class = row[relationship_idx]\n",
    "            boxes = row[3:11]\n",
    "            k = (subject_class, object_class, relationship_class)\n",
    "            if k in ret_dict:\n",
    "                if fid in ret_dict[k]:\n",
    "                    ret_dict[k][fid].append(boxes)\n",
    "                else:\n",
    "                    ret_dict[k][fid] = [boxes]\n",
    "            else:\n",
    "                ret_dict[k] = {fid: [boxes]}\n",
    "    return ret_dict\n",
    "\n",
    "def get_triplet_to_image_id_dict_from_data_set(model_data_input):\n",
    "    \"\"\"\n",
    "    When not considering bounding box data dimension for train and test set we only have a \n",
    "    constrained set of triplets. Get them for evaluation.\n",
    "    \"\"\"\n",
    "    ret_dict = {}\n",
    "\n",
    "    for fid, boxes, labels_orig in zip(model_data_input['id'], model_data_input['boxes'], \n",
    "                                       model_data_input['labels_orig']):\n",
    "        k = labels_orig\n",
    "        if k not in ret_dict:\n",
    "            ret_dict[k] = {}\n",
    "\n",
    "        if fid not in ret_dict[k]:\n",
    "            ret_dict[k][fid] = []\n",
    "  \n",
    "        ret_dict[k][fid].append(boxes)\n",
    "\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header for validation/stage2_model_epoch_10_testset_val.csv: ['ImageID', 'LabelName1', 'LabelName2', 'XMin1', 'XMax1', 'YMin1', 'YMax1', 'XMin2', 'XMax2', 'YMin2', 'YMax2', 'RelationshipLabel', 'Score']\n"
     ]
    }
   ],
   "source": [
    "ground_truth_triplet_dict = get_triplet_to_image_id_dict_from_data_set(model_data_input=model_test_dataset)\n",
    "model_test_triplet_dict, model_test_rel_dict = get_triplets_from_dataset(model_test_dataset)\n",
    "testset_triplet_dict = get_triplet_to_image_id_dict_from_csv(csv_fname=validation_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model test triplet keys length: 252\n",
      "testset triplet_keys lenth: 80\n"
     ]
    }
   ],
   "source": [
    "print ('model test triplet keys length: {}'.format(len(ground_truth_triplet_dict.keys())))\n",
    "print ('testset triplet_keys lenth: {}'.format(len(testset_triplet_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_per_class_precision_recall_dict(ground_truth_triplet_dict, testset_triplet_dict):\n",
    "    class_dict = {}\n",
    "    for triplet, v in testset_triplet_dict.items():\n",
    "        #print('Triplet: {}'.format(triplet))\n",
    "        detection_count = len(v.keys())        \n",
    "        true_positives = 0.0\n",
    "        ground_truth_count = 0.0\n",
    "        if triplet in ground_truth_triplet_dict:\n",
    "            result_fid_set = set(v.keys())\n",
    "            ground_fid_set = set(ground_truth_triplet_dict[triplet].keys())\n",
    "            ground_truth_count  = len(ground_fid_set)\n",
    "            true_positives = len(result_fid_set.intersection(ground_fid_set))\n",
    "        #print ('+ive: {}, detection_count: {}'.format(true_positives, detection_count))\n",
    "        precision = float(true_positives)/float(detection_count)\n",
    "        if ground_truth_count != 0.0:\n",
    "            recall = float(true_positives)/float(ground_truth_count)\n",
    "        else:\n",
    "            recall = None  # Invalid triplet!.\n",
    "        class_dict[triplet] = (precision, recall)\n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triplet_precision_recall = get_per_class_precision_recall_dict(ground_truth_triplet_dict, testset_triplet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing label count: 0\n"
     ]
    }
   ],
   "source": [
    "xy_list, train_data_label_tuple, label_dict = process_raw_csv_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per triplet precision and recall\n",
    "\n",
    "List the precision and recall obtained per triplet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man-at-Table:0.305556,0.008558\n"
     ]
    }
   ],
   "source": [
    "for k, v in triplet_precision_recall.items():\n",
    "    #print ('Triplet: {}'.format(k))\n",
    "    if v[1] is not None:\n",
    "        print ('{}-{}-{}:{},{}'.format(label_dict[k[0]], k[2], label_dict[k[1]], \n",
    "            round(float(v[0]), 6), round(float(v[1]), 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
