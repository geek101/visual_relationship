{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Visual Relationship project\n",
    "This project is based on the [Google AI Open Images - Visual Relationship Track Kaggle Challenge](https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track).\n",
    "\n",
    "The challenge is to build the best performing algorithm for automatically detecting relationships triplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using COCO trained weights: resnet50_coco_best_v2.1.0.h5 from path: /home/powell/work/scpd/vision_project/visual_relationship/pretrained_models/resnet50_coco_best_v2.1.0.h5, downloaded from: https://github.com/fizyr/keras-retinanet/releases/download/0.5.0/resnet50_coco_best_v2.1.0.h5\n",
      "Keras version: 2.2.4\n",
      "Tensorflow version: 1.4.0\n",
      "Tensorflow lib config: /home/powell/ENTER/envs/carnd-term1/lib/python3.5/site-packages/tensorflow\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import wget\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "import collections\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import parallel \n",
    "import concurrent.futures\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras import __version__ as keras_version\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Lambda, Cropping2D, Reshape, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# https://github.com/fizyr/keras-retinanet/blob/master/examples/ResNet50RetinaNet.ipynb\n",
    "import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image, compute_resize_scale\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "#def get_session():\n",
    "#    config = tf.ConfigProto()\n",
    "#    config.gpu_options.allow_growth = True\n",
    "#    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "#keras.backend.tensorflow_backend.set_session(get_session())\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "# https://github.com/fizyr/keras-retinanet/releases/download/0.5.0/resnet50_coco_best_v2.1.0.h5\n",
    "RCNN_COCO_MODEL_URL = \"https://github.com/fizyr/keras-retinanet/releases/download/0.5.0/resnet50_coco_best_v2.1.0.h5\"\n",
    "RCNN_COCO_MODEL = \"resnet50_coco_best_v2.1.0.h5\"\n",
    "\n",
    "# Local path to trained weights file\n",
    "MODEL_PATH = os.path.join(os.path.join(os.getcwd(), \"pretrained_models\"), RCNN_COCO_MODEL)\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print ('Downloading COCO trained weights: {} to path: {}'.format(RCNN_COCO_MODEL, MODEL_PATH))  \n",
    "    wget.download(RCNN_COCO_MODEL_URL, MODEL_PATH)  \n",
    "else:\n",
    "    print ('Using COCO trained weights: {} from path: {}, downloaded from: {}'.format(\n",
    "        RCNN_COCO_MODEL, MODEL_PATH, RCNN_COCO_MODEL_URL))\n",
    "    \n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "print ('Keras version: {}'.format(keras_version))\n",
    "print ('Tensorflow version: {}'.format(tf.__version__))\n",
    "print ('Tensorflow lib config: {}'.format(tf.sysconfig.get_lib()))\n",
    "\n",
    "from helpers import get_fid, process_labels_from_csv_input, process_raw_csv_input, get_data_dir_from_raw_single_dir \n",
    "from helpers import get_data_from_dir_recursive, bounding_box_to_plt, two_bounding_boxes_to_plt, show_images\n",
    "from helpers import show_given_images, show_random_images, _resize_job_helper, chunks, resize_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels loaded:61\n",
      "0: /m/078n6m-Coffee table\n",
      "1: /m/01mzpv-Chair\n",
      "2: /m/01226z-Football\n",
      "3: /m/0h2r6-Van\n",
      "4: /m/0pg52-Taxi\n",
      "5: /m/0cvnqh-Bench\n",
      "6: /m/0hg7b-Microphone\n",
      "7: /m/0dnr7-Textile\n",
      "8: /m/080hkjn-Handbag\n",
      "9: /m/01f91_-Pretzel\n",
      "10: /m/0k4j-Car\n",
      "11: /m/078jl-Snake\n",
      "12: /m/04_sv-Motorcycle\n",
      "13: /m/0bwd_0j-Elephant\n",
      "14: /m/02hj4-Dolphin\n",
      "15: /m/029bxz-Oven\n",
      "16: /m/019w40-Surfboard\n",
      "17: /m/01s55n-Suitcase\n",
      "18: /m/05r655-Girl\n",
      "19: /m/01yrx-Cat\n",
      "20: /m/05z87-Plastic\n",
      "21: /m/03k3r-Horse\n",
      "22: /m/050k8-Mobile phone\n",
      "23: /m/0fx9l-Microwave oven\n",
      "24: /m/0199g-Bicycle\n",
      "25: /m/0h8my_4-Tennis racket\n",
      "26: /m/04bcr3-Table\n",
      "27: /m/07y_7-Violin\n",
      "28: /m/04yx4-Man\n",
      "29: /m/0584n8-Briefcase\n",
      "30: /m/01599-Beer\n",
      "31: /m/09tvcd-Wine glass\n",
      "32: /m/0342h-Guitar\n",
      "33: /m/04dr76w-Bottle\n",
      "34: /m/0cmx8-Spoon\n",
      "35: /m/026t6-Drum\n",
      "36: /m/071p9-Ski\n",
      "37: /m/0bt9lr-Dog\n",
      "38: /m/08pbxl-Monkey\n",
      "39: /m/03bt1vf-Woman\n",
      "40: /m/01bl7v-Boy\n",
      "41: /m/0l14j_-Flute\n",
      "42: /m/04ctx-Knife\n",
      "43: /m/05r5c-Piano\n",
      "44: /m/0dv9c-Racket\n",
      "45: /m/01940j-Backpack\n",
      "46: /m/03ssj5-Bed\n",
      "47: /m/02jvh9-Mug\n",
      "48: /m/05ctyq-Tennis ball\n",
      "49: /m/01_5g-Chopsticks\n",
      "50: /m/03qrc-Hamster\n",
      "51: /m/06__v-Snowboard\n",
      "52: /m/04lbp-Leather\n",
      "53: /m/083vt-Wood\n",
      "54: /m/0dt3t-Fork\n",
      "55: /m/05_5p_0-Table tennis racket\n",
      "56: /m/0wdt60w-Rugby ball\n",
      "57: /m/03m3pdh-Sofa bed\n",
      "58: /m/0dv5r-Camera\n",
      "59: /m/02p5f1q-Coffee cup\n",
      "60: /m/01y9k5-Desk\n",
      "Number of unique labels from training data loaded: 61\n",
      "Number of unique labels from test data loaded: 59\n",
      "Total missing label count: 2\n",
      "/m/029bxz-Oven\n",
      "/m/0fx9l-Microwave oven\n"
     ]
    }
   ],
   "source": [
    "annotations_file='fullsize_train_annotations.csv'\n",
    "annotations_test_file='fullsize_test_annotations.csv'\n",
    "classes_file='fullsize_classes.csv'\n",
    "# Load the labels\n",
    "label_tag_to_name = process_labels_from_csv_input()\n",
    "def load_labels(label_tag_to_name, labels_file=classes_file):\n",
    "    labels_to_names = {}\n",
    "    # Process the labels info files and create a key value pair\n",
    "    with open(labels_file, encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            labels_to_names[int(row[1])]= (label_tag_to_name[row[0]], row[0])\n",
    "    return labels_to_names\n",
    "\n",
    "labels_to_names = load_labels(label_tag_to_name, labels_file=classes_file)\n",
    "#print(label_tag_to_name)\n",
    "print (\"Number of labels loaded:{}\".format(len(labels_to_names)))\n",
    "for k, v in sorted(labels_to_names.items()):\n",
    "    print (\"{}: {}-{}\".format(k, v[1], v[0]))\n",
    "\n",
    "def load_labels_and_dataset_from_data(label_tag_to_name, data_file=annotations_file):\n",
    "    labels_to_names = {}\n",
    "    # Process the labels info files and create a key value pair\n",
    "    with open(data_file, encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            \n",
    "            labels_to_names[row[-1]] = label_tag_to_name[row[-1]]\n",
    "    return labels_to_names\n",
    "\n",
    "train_labels_to_names = load_labels_and_dataset_from_data(label_tag_to_name, data_file=annotations_file)\n",
    "print (\"Number of unique labels from training data loaded: {}\".format(len(train_labels_to_names)))\n",
    "   \n",
    "test_labels_to_names = load_labels_and_dataset_from_data(label_tag_to_name, data_file=annotations_test_file)\n",
    "print (\"Number of unique labels from test data loaded: {}\".format(len(test_labels_to_names)))\n",
    "\n",
    "missing_label_set = set(train_labels_to_names.keys()) - set(test_labels_to_names.keys())\n",
    "print (\"Total missing label count: {}\".format(len(missing_label_set)))\n",
    "for l in missing_label_set:\n",
    "    print (\"{}-{}\".format(l, label_tag_to_name[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the inference data and prep it for next stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training y data size: 87547\n",
      "Test y data size: 18012\n"
     ]
    }
   ],
   "source": [
    "infer_result_dir_prefix = 'fullsize_infer_output'\n",
    "infer_train_result_dir = 'train_y'\n",
    "infer_test_result_dir = 'test_y'\n",
    "\n",
    "def load_y_data(prefix=infer_result_dir_prefix, y_data_dir=infer_train_result_dir):\n",
    "    cwd = os.getcwd()\n",
    "    flist = glob.glob(os.path.join(os.path.join(os.path.join(cwd, prefix), y_data_dir), '*.p.npy'))\n",
    "    y_data = {}\n",
    "    for f in flist:\n",
    "        fid = os.path.basename(f).split('.')[0]\n",
    "        assert fid not in y_data\n",
    "        y_data[fid] = np.load(f)\n",
    "    return y_data\n",
    "\n",
    "infer_y_train = load_y_data(prefix=infer_result_dir_prefix, y_data_dir=infer_train_result_dir)\n",
    "print (\"Training y data size: {}\".format(len(infer_y_train)))\n",
    "\n",
    "infer_y_test = load_y_data(prefix=infer_result_dir_prefix, y_data_dir=infer_test_result_dir)\n",
    "print (\"Test y data size: {}\".format(len(infer_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape on an example: (100, 6)\n",
      "Example 1 index: [  8.08266602e+02   5.53883743e+01   9.28702026e+02   3.41990082e+02\n",
      "   3.04418266e-01   3.90000000e+01]\n",
      "Image size: 96499\n",
      "Train and test len: 105559\n"
     ]
    }
   ],
   "source": [
    "k = list(infer_y_train.keys())[0]\n",
    "print (\"Shape on an example: {}\".format(infer_y_train[k].shape))\n",
    "print (\"Example 1 index: {}\".format(infer_y_train[k][0]))\n",
    "\n",
    "image_size_cache_file='image_size_cache.p'\n",
    "with open(image_size_cache_file, 'rb') as f:\n",
    "    image_size_cache = pickle.load(f)\n",
    "    \n",
    "# All images covered.\n",
    "print (\"Image size: {}\".format(len(image_size_cache)))\n",
    "print (\"Train and test len: {}\".format(len(infer_y_train) + len(infer_y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the training and test set for our model using\n",
    "\n",
    "Using the inference output and iterating over the inference output of training and test data\n",
    "create the training and test set for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the pickle files corresponding to the orignal train test set split.\n",
    "fullsize_train_model_file = 'fullsize_train_model.p'\n",
    "fullsize_test_model_file = 'fullsize_test_model.p'\n",
    "\n",
    "with open(fullsize_train_model_file, 'rb') as f:\n",
    "    fullsize_train_model_data = pickle.load(f)\n",
    "with open(fullsize_test_model_file, 'rb') as f:\n",
    "    fullsize_test_model_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of loaded data: dict_keys(['boxes', 'features', 'labels_orig'])\n",
      "Example 1: features: /home/powell/work/scpd/vision_project/visual_relationship/data/processed/raw/train_07/241d4c0143f2c91f.jpg\n",
      "Example 1: boxes: ['0', '0.88625', '0.4283019', '0.9981132', '0', '0.88625', '0.4283019', '0.9981132']\n",
      "Example 1: labels_orig: ('/m/04bcr3', '/m/083vt', 'is')\n",
      "Size of training set: 77325\n",
      "Size of test set: 16645\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the training dict and create training set\n",
    "print ('Keys of loaded data: {}'.format(fullsize_train_model_data.keys()))\n",
    "print ('Example 1: features: {}'.format(fullsize_train_model_data['features'][0]))\n",
    "print ('Example 1: boxes: {}'.format(fullsize_train_model_data['boxes'][0]))\n",
    "print ('Example 1: labels_orig: {}'.format(fullsize_train_model_data['labels_orig'][0]))\n",
    "\n",
    "def group_by_image(model_data):\n",
    "    image_group = {}\n",
    "    for image_path, boxes, labels in zip(model_data['features'], \n",
    "                                         model_data['boxes'],\n",
    "                                         model_data['labels_orig']):\n",
    "        fid = os.path.basename(image_path).split('.')[0]\n",
    "        if fid not in image_group:\n",
    "            image_group[fid] = {}\n",
    "\n",
    "        triplet = (labels[0], labels[1], labels[2])\n",
    "        if triplet not in image_group[fid]:\n",
    "            image_group[fid][triplet] = []\n",
    "            \n",
    "        image_group[fid][triplet].append(boxes)\n",
    "    image_group_triplet_sorted = {}\n",
    "    for k, v in image_group.items():\n",
    "        l = sorted(v.items(), key=lambda kv: len(kv[1]), reverse=True)\n",
    "        image_group_triplet_sorted[k] = [l[0]]  # Take the best triplet only :(\n",
    "    return image_group_triplet_sorted         \n",
    "\n",
    "        \n",
    "def create_dataset_from_infer(grouped_model_data, y_data, shape_restrict=(100, 6)):\n",
    "    dataset = {'id': [], 'features': [], 'boxes': [], 'labels_orig': [], \n",
    "               'label_subject_orig': [], 'label_object_orig': [], 'label_rel_orig': []}\n",
    "    for fid, triplet_list in grouped_model_data.items():\n",
    "        #assert fid not in y_data\n",
    "        labels = triplet_list[0][0]  # Most used triplet labels only\n",
    "        boxes = triplet_list[0][1]   # Most used triplet boxes only\n",
    "        if fid in y_data and y_data[fid].shape == shape_restrict:\n",
    "            dataset['id'].append(fid)\n",
    "            dataset['features'].append(y_data[fid].reshape(-1))\n",
    "            dataset['boxes'].append(np.asarray(boxes))\n",
    "            dataset['labels_orig'].append(labels)\n",
    "            dataset['label_subject_orig'].append(labels[0])\n",
    "            dataset['label_object_orig'].append(labels[1])\n",
    "            dataset['label_rel_orig'].append(labels[2])\n",
    "    return dataset\n",
    "\n",
    "model_train_grouped = group_by_image(model_data=fullsize_train_model_data)\n",
    "model_train_dataset = create_dataset_from_infer(grouped_model_data=model_train_grouped, y_data=infer_y_train)\n",
    "print ('Size of training set: {}'.format(len(model_train_dataset['id'])))\n",
    "\n",
    "model_test_grouped = group_by_image(model_data=fullsize_test_model_data)\n",
    "model_test_dataset = create_dataset_from_infer(grouped_model_data=model_test_grouped, y_data=infer_y_test)\n",
    "print ('Size of test set: {}'.format(len(model_test_dataset['id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training triplets length: 298\n",
      "Model test triplets length: 268\n"
     ]
    }
   ],
   "source": [
    "def get_triplets(model_grouped):\n",
    "    ret_dict = collections.defaultdict(int)\n",
    "    for k, v in model_grouped.items():\n",
    "        ret_dict[v[0][0]] += 1\n",
    "    return ret_dict\n",
    "\n",
    "model_train_triplet_dict = get_triplets(model_train_grouped)\n",
    "model_test_triplet_dict = get_triplets(model_test_grouped)\n",
    "\n",
    "print ('Model training triplets length: {}'.format(len(model_train_triplet_dict.keys())))\n",
    "print ('Model test triplets length: {}'.format(len(model_test_triplet_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training triplets length: 292\n",
      "Model test triplets length: 231\n",
      "Model training relationships: [('is', 39807), ('at', 16890), ('holds', 7917), ('on', 6814), ('interacts_with', 2062), ('plays', 2014), ('inside_of', 1232), ('hits', 409), ('wears', 169), ('under', 11)]\n",
      "Model test relationships: [('is', 8090), ('at', 4799), ('on', 1454), ('holds', 1243), ('plays', 481), ('interacts_with', 285), ('inside_of', 199), ('hits', 57), ('wears', 33), ('under', 4)]\n"
     ]
    }
   ],
   "source": [
    "def get_triplets_from_dataset(model_dataset):\n",
    "    ret_dict = collections.defaultdict(int)\n",
    "    rel_dict = collections.defaultdict(int)\n",
    "    for t in model_dataset['labels_orig']:\n",
    "        ret_dict[t] += 1\n",
    "        rel_dict[t[2]] += 1\n",
    "    return ret_dict, rel_dict\n",
    "\n",
    "model_train_triplet_dict, model_train_rel_dict = get_triplets_from_dataset(model_train_dataset)\n",
    "model_test_triplet_dict, model_test_rel_dict = get_triplets_from_dataset(model_test_dataset)\n",
    "\n",
    "print ('Model training triplets length: {}'.format(len(model_train_triplet_dict.keys())))\n",
    "print ('Model test triplets length: {}'.format(len(model_test_triplet_dict.keys())))\n",
    "\n",
    "print ('Model training relationships: {}'.format(sorted(model_train_rel_dict.items(), key=lambda kv: kv[1], reverse=True)))\n",
    "print ('Model test relationships: {}'.format(sorted(model_test_rel_dict.items(), key=lambda kv: kv[1], reverse=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size: 77325\n",
      "Test data set size: 16645\n",
      "Before Multi-Encoding feature shape: (600,), label: ('/m/05r655', '/m/0cvnqh', 'on'), label_subject: /m/05r655,        label_object: /m/0cvnqh, label_relationship: on\n",
      "After Multi-Encoding feature shape: (600,), subject label: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "MLB classes size object/subject: 61, classes: ['/m/01226z' '/m/01599' '/m/01940j' '/m/0199g' '/m/019w40' '/m/01_5g'\n",
      " '/m/01bl7v' '/m/01f91_' '/m/01mzpv' '/m/01s55n' '/m/01y9k5' '/m/01yrx'\n",
      " '/m/026t6' '/m/029bxz' '/m/02hj4' '/m/02jvh9' '/m/02p5f1q' '/m/0342h'\n",
      " '/m/03bt1vf' '/m/03k3r' '/m/03m3pdh' '/m/03qrc' '/m/03ssj5' '/m/04_sv'\n",
      " '/m/04bcr3' '/m/04ctx' '/m/04dr76w' '/m/04lbp' '/m/04yx4' '/m/050k8'\n",
      " '/m/0584n8' '/m/05_5p_0' '/m/05ctyq' '/m/05r5c' '/m/05r655' '/m/05z87'\n",
      " '/m/06__v' '/m/071p9' '/m/078jl' '/m/078n6m' '/m/07y_7' '/m/080hkjn'\n",
      " '/m/083vt' '/m/08pbxl' '/m/09tvcd' '/m/0bt9lr' '/m/0bwd_0j' '/m/0cmx8'\n",
      " '/m/0cvnqh' '/m/0dnr7' '/m/0dt3t' '/m/0dv5r' '/m/0dv9c' '/m/0fx9l'\n",
      " '/m/0h2r6' '/m/0h8my_4' '/m/0hg7b' '/m/0k4j' '/m/0l14j_' '/m/0pg52'\n",
      " '/m/0wdt60w']\n",
      "MLB classes size relationship: 10, classes: ['at' 'hits' 'holds' 'inside_of' 'interacts_with' 'is' 'on' 'plays' 'under'\n",
      " 'wears']\n",
      "Training data label set size: 77325\n",
      "Test data label set size: 16645\n"
     ]
    }
   ],
   "source": [
    "print ('Training data set size: {}'.format(len(model_train_dataset['features'])))\n",
    "print ('Test data set size: {}'.format(len(model_test_dataset['features'])))  \n",
    "\n",
    "classes_file='fullsize_classes.csv'\n",
    "label_tag_to_name = process_labels_from_csv_input()\n",
    "labels_to_names = load_labels(label_tag_to_name, labels_file=classes_file)\n",
    "\n",
    "print ('Before Multi-Encoding feature shape: {}, label: {}, label_subject: {}, \\\n",
    "       label_object: {}, label_relationship: {}'.format(model_train_dataset['features'][0].shape, \n",
    "                                                        model_test_dataset['labels_orig'][0],\n",
    "                                                        model_test_dataset['label_subject_orig'][0],\n",
    "                                                        model_test_dataset['label_object_orig'][0],\n",
    "                                                        model_test_dataset['label_rel_orig'][0]))\n",
    "\n",
    "# label encoding\n",
    "mlb_subject_object = LabelBinarizer()\n",
    "mlb_subject_object = mlb_subject_object.fit([ v[1] for k, v in labels_to_names.items() ])\n",
    "\n",
    "mlb_relationship = LabelBinarizer()\n",
    "mlb_relationship = mlb_relationship.fit(model_train_dataset['label_rel_orig'] + \n",
    "                                        model_test_dataset['label_rel_orig'])\n",
    "         \n",
    "# 1 hot vector encoding for subject/object\n",
    "model_train_dataset['label_subject'] = mlb_subject_object.transform(model_train_dataset['label_subject_orig'])\n",
    "model_test_dataset['label_subject'] = mlb_subject_object.transform(model_test_dataset['label_subject_orig'])\n",
    "model_train_dataset['label_object'] = mlb_subject_object.transform(model_train_dataset['label_subject_orig'])\n",
    "model_test_dataset['label_object'] = mlb_subject_object.transform(model_test_dataset['label_subject_orig'])\n",
    "\n",
    "# 1 hot vector encoding for relationship\n",
    "model_train_dataset['label_rel'] = mlb_relationship.transform(model_train_dataset['label_rel_orig'])\n",
    "model_test_dataset['label_rel'] = mlb_relationship.transform(model_test_dataset['label_rel_orig'])\n",
    "                  \n",
    "print ('After Multi-Encoding feature shape: {}, subject label: {}'.format(model_train_dataset['features'][0].shape, \n",
    "                                                                 model_train_dataset['label_subject'][0]))\n",
    "print('MLB classes size object/subject: {}, classes: {}'.format(len(mlb_subject_object.classes_), \n",
    "                                                                mlb_subject_object.classes_))\n",
    "print('MLB classes size relationship: {}, classes: {}'.format(len(mlb_relationship.classes_), \n",
    "                                                                mlb_relationship.classes_))\n",
    "print ('Training data label set size: {}'.format(len(model_train_dataset['label_subject'])))\n",
    "print ('Test data label set size: {}'.format(len(model_test_dataset['label_subject']))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling - Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (77325, 600)\n",
      "Boxes shape: (1, 8)\n",
      "Subject labels shape: (61,)\n",
      "Object labels shape: (61,)\n",
      "Relationship labels shape: (10,)\n",
      "Shape of y_test[0]: (77325,), y_test[1]: (77325,)\n",
      "Shape of X_test: (16645, 600)\n",
      "Shape of y_test[0]: (77325,), y_test[1]: (16645, 61), y_test[2]: (16645, 61), y_test[3]: (16645, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(model_train_dataset['features'])\n",
    "print('Shape of X_train: {}'.format(X_train.shape))\n",
    "print ('Boxes shape: {}'.format(model_train_dataset['boxes'][0].shape))\n",
    "print ('Subject labels shape: {}'.format(model_train_dataset['label_subject'][0].shape))\n",
    "print ('Object labels shape: {}'.format(model_train_dataset['label_object'][0].shape))\n",
    "print ('Relationship labels shape: {}'.format(model_train_dataset['label_rel'][0].shape))\n",
    "\n",
    "# Sequence of labels are boxes, subject, object and relationship\n",
    "y_train = [np.asarray(model_train_dataset['boxes']), \n",
    "           np.asarray(model_train_dataset['label_subject']),\n",
    "           np.asarray(model_train_dataset['label_object']),\n",
    "           np.asarray(model_train_dataset['label_rel'])]\n",
    "\n",
    "print('Shape of y_test[0]: {}, y_test[1]: {}'.format(y_train[0].shape, y_train[0].shape))\n",
    "X_test = np.asarray(model_test_dataset['features'])\n",
    "print('Shape of X_test: {}'.format(X_test.shape))\n",
    "y_test = [np.asarray(model_train_dataset['boxes']), \n",
    "          np.array(model_test_dataset['label_subject']),\n",
    "          np.array(model_test_dataset['label_object']),\n",
    "          np.array(model_test_dataset['label_rel'])]\n",
    "print('Shape of y_test[0]: {}, y_test[1]: {}, y_test[2]: {}, y_test[3]: {}'.format(\n",
    "    y_test[0].shape, y_test[1].shape, y_test[2].shape, y_test[3].shape))\n",
    "\n",
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train = std_scale.transform(X_train)\n",
    "X_test = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example train 1: [ 2.30476513 -1.55111804  0.946195   -2.21375896 -1.63143538  1.11326003\n",
      "  1.62579324 -0.73336721  1.14203743 -2.08839704 -1.60753007  0.03989343\n",
      "  1.46834614 -0.98847048  0.61472989 -2.07187138 -1.44191008 -1.537494\n",
      "  1.93715409 -1.4439172   1.09913769 -1.86660273 -1.12902393  0.21264154\n",
      "  1.60286758 -1.08196701  1.19581253 -1.87437201 -1.50277761 -1.47240353\n",
      "  1.89759088 -1.54828243  1.10862103 -1.81480853 -1.38197016 -0.39240401\n",
      " -1.03869305  0.37518626 -1.99367051 -0.87552212 -1.34316586 -1.43730992\n",
      "  1.92030143 -1.32616157  1.11024295 -1.82241732 -1.35340623 -1.42473504\n",
      "  1.40007982 -0.95560896  1.25338824 -1.84158927 -1.20666618 -1.16058621\n",
      "  1.8548597  -1.55079528  1.12964541 -1.77002157 -1.18894275  1.01615254\n",
      " -0.38454295 -0.14345482  1.39025287  0.17025324 -1.08411491 -1.13931352\n",
      "  1.43674169 -1.3108527   1.16041195 -1.77430797 -1.10298545  0.28150981\n",
      "  1.97443884 -0.79628096  1.13408748 -1.73078695 -0.9932918   0.03935141\n",
      "  0.98225983 -0.30963223  1.50655739  0.25793288 -1.13993928  0.16555823\n",
      "  1.88240417 -0.98222149  1.18316481 -1.93844092 -1.09971084  0.72951415\n",
      "  1.38041665 -1.09853334  0.65816643 -2.17497866 -1.06277085 -1.36148474\n",
      "  0.63412118 -1.43244353  0.25268193 -1.62767758 -1.06188177 -1.36007208\n",
      "  1.48156315 -1.17738818  1.24845112 -1.66485715 -1.00829936  0.97762692\n",
      "  1.89124829 -1.05342743  1.32481133 -1.77018459 -1.07322272 -1.35362651\n",
      "  1.31532328 -1.11494354  0.92594028 -1.73028018 -1.20534591  0.18764374\n",
      "  1.48516943 -1.57548006  1.06126348 -1.8935266  -1.16856159  0.98985935\n",
      "  1.08486564  0.59891138  0.82717322  0.02142671 -1.17571562 -1.34362003\n",
      "  1.91267313 -0.75478596  1.15938629 -1.69512695 -1.16572543  0.74570539\n",
      "  1.63542592 -1.75274483  1.40952983 -1.34502769 -1.14511768  0.99028316\n",
      "  1.74566322 -1.02793974  1.41034744 -1.57281824 -1.09158221  0.19309839\n",
      "  1.70683352 -1.54981536  1.37910716 -1.46318365 -1.05552513 -1.34170107\n",
      "  1.73743861 -1.585911    1.20260083 -2.35579041 -1.13577889  0.9946534\n",
      " -0.20428925 -0.1990985   1.27467126  0.07554122 -1.12649342  0.20101845\n",
      "  1.25536406 -1.49788018  1.07224392 -1.73622563 -1.10607647 -1.32891584\n",
      "  2.20082765 -1.14535696  1.55718894 -2.01170104 -1.07577834 -1.33074133\n",
      "  1.90026151 -1.452902    1.26155454 -1.70481452 -1.05365624  0.98712999\n",
      "  0.68973213 -1.42758592  0.21560715 -2.54174847 -1.03624141 -1.32931595\n",
      "  1.29874776 -1.25737712  0.83332732 -1.67327986 -1.05298886  0.99542113\n",
      "  1.34298926 -1.07527195  0.86201078 -1.9014502  -1.01638367 -1.32264528\n",
      "  0.63811735 -1.25825915  1.52862152  0.0305973  -0.97779662 -1.08289889\n",
      "  0.61226475 -1.57698135  0.24716961 -1.46847717 -0.95150813 -0.89957117\n",
      " -0.90545912 -0.91281416  1.29232633 -0.17141268 -0.91822989 -1.0818971\n",
      "  1.69550575 -1.63080017  1.21171765 -2.30060809 -0.90539306  0.3245771\n",
      "  1.24361452 -1.120174    1.47048682 -0.8955431  -0.98899715  0.20461422\n",
      " -1.2252861   0.23416362 -1.2250622  -0.5887379  -0.96175128 -1.08014337\n",
      "  2.04667164 -1.09761186  1.5216942  -1.66392632 -0.93231222 -1.32249309\n",
      "  1.44740346 -0.90745886  0.90619096 -1.81738985 -0.90141251 -1.32364634\n",
      "  1.4004546  -1.218653    1.2924407  -1.51976256 -0.91195923 -0.27989644\n",
      "  1.23514052 -0.71181779  0.86339096 -1.7055822  -0.94652753  0.20301372\n",
      "  1.23477756  0.64057152  0.86213667 -0.15670412 -0.93229172 -1.3064726\n",
      "  1.5047837  -1.35701718  0.96420524 -1.69036239 -0.91805608 -1.30974761\n",
      "  1.24709129 -1.01916815  0.59682195 -1.71134401 -0.93523959 -1.31318761\n",
      " -1.30585977  0.2155493  -1.74309652 -0.54051537 -0.91621389 -1.07410151\n",
      "  1.95492086 -1.13851221  1.57570593 -1.56110276 -0.92125826  0.20931536\n",
      "  1.69659005 -1.39758876  1.11255151 -1.84292775 -0.97959092  1.0033315\n",
      "  1.54815992 -1.74451888  1.4496706  -1.13029573 -1.00073427  0.33444459\n",
      "  1.93920251 -1.43263807  1.56593405 -1.41680663 -0.98110821  0.32653138\n",
      "  1.90105375 -1.58567169  1.52645368 -1.44896789 -0.96790479  1.00661535\n",
      "  1.82940141 -0.91263315  1.20869133 -1.49817259 -0.94735825 -0.64323941\n",
      "  1.79494019 -1.10272888  1.22143391 -2.08715881 -0.93109677  0.75916118\n",
      "  1.65888908 -1.10399484  1.25102224 -2.06458675 -0.9432809   0.56941674\n",
      "  1.24392499 -1.27462556  0.85473837 -1.57814553 -0.92298337  0.33278283\n",
      "  1.67065582 -1.07398278  1.16227172 -1.93295303 -0.93454717  0.75876526\n",
      "  1.66974623 -1.41045061  1.11634463 -1.8208799  -0.91501826  0.33906632\n",
      "  1.16143002 -0.67318364  0.81646247 -1.60077592 -0.91099203 -1.07551544\n",
      "  1.82364266 -0.91088783  1.21760584 -1.48118062 -0.89473761  0.32516701\n",
      "  1.67001889 -1.10216569  1.21811837 -1.82733066 -0.87507057 -1.31161965\n",
      " -1.28365984  0.28286773 -1.73260469 -0.58116112 -0.8678786  -1.31084085\n",
      "  1.45893966 -1.66711627  1.0735079  -1.64394954 -0.87479267  0.33098977\n",
      "  0.79812007  0.22047261  1.33180716  0.40839802 -0.88805943 -1.06863812\n",
      "  1.19930937 -1.04481152  1.04950467 -1.49510726 -0.87149757 -1.37158822\n",
      "  1.20079392 -1.15864631  0.97651282 -1.54082099 -0.88826662  2.10131233\n",
      "  1.55512338 -1.31685618  1.17798715 -1.45366383 -0.88596672  0.21624019\n",
      "  1.29230765 -1.38399526  1.24225708 -1.48558    -0.89017935  1.05817639\n",
      "  0.14608217 -0.9835009   1.58119404 -0.06315952 -0.87191476  0.20517348\n",
      "  1.19447837 -0.65751286  1.02969594 -1.44977297 -0.8677965   0.21263816\n",
      "  1.68137368 -0.87773092  1.13604763 -1.72682745 -0.8549704   0.75617669\n",
      "  0.91066494 -0.82274113  1.3964451  -1.17386158 -0.83649118  0.20803136\n",
      "  1.53387119 -1.23113842  1.12903121 -1.90498432 -0.82279816 -1.3096131\n",
      "  0.84102439 -1.18592928  0.95752803 -1.48289135 -0.81564663 -1.30631967\n",
      "  1.26083144 -0.83024875  0.879941   -1.58840725 -0.79809897 -1.30301378\n",
      "  1.84045359 -0.99257151  1.19560917 -1.77429573 -0.79606354  0.75764019\n",
      "  1.49350872 -1.0237083   0.86419136 -1.77785317 -0.79601412 -1.304913\n",
      "  1.62243512 -0.98027118  1.20852162 -1.63938812 -0.77904193  0.09030466\n",
      "  1.19523604 -1.14887868  0.77012577 -1.79308129 -0.79713484  0.20490818\n",
      "  1.1606271  -0.6721457   0.68505065 -1.56164088 -0.80311966 -1.31555347\n",
      "  1.18977863 -1.40919696  0.99267516 -1.43881775 -0.83437658 -0.2776272\n",
      "  1.7671876  -1.32500915  1.23573141 -1.74586905 -0.82063727  0.33183049\n",
      "  1.81205235 -1.48407144  1.31138407 -1.53787491 -0.80716504  1.06693543\n",
      "  1.63676375 -1.41549678  1.22409664 -1.99855928 -0.81236271  1.36081516\n",
      "  1.82381603 -1.28893494  1.32517484 -1.44644831 -0.8016258   0.32835049\n",
      "  1.63845878 -1.41180042  1.23584687 -1.99804507 -0.81569766 -1.31385497\n",
      "  1.77970953 -0.92750689  1.22029602 -1.41646713 -0.81375996  1.36727771\n",
      "  1.61912951 -1.11377772  1.26905152 -1.97355001 -0.81724677  0.09501832\n",
      " -1.31180038  0.13693558 -1.0383203  -0.43198771 -0.82053198  0.21278332\n",
      "  1.22776278 -1.04523769  1.26772576 -1.509504   -0.8206297   2.27245455\n",
      "  1.48658618 -1.4103274   1.38277279 -1.90991542 -0.80889418  1.0054426\n",
      "  1.76257671 -1.43431807  1.34152631 -1.38602445 -0.80698368 -0.27487041\n",
      "  1.65910061 -1.64777433  1.22303513 -2.06616929 -0.80306723 -0.27816125\n",
      "  1.64630945 -1.67175561  1.24008425 -1.38032086 -0.79551822  1.36093878\n",
      " -0.02390616  0.45842862  1.57620377  0.87541906 -0.79246578 -1.05576022\n",
      "  1.61628342 -1.17971178  1.22524915 -1.85905948 -0.78237248 -0.88072319\n",
      "  1.14846771 -1.01942816  0.66897453 -1.49797115 -0.7700485  -1.05836291\n",
      "  1.58543156 -0.98301818  1.20545734 -1.59535048 -0.75986092 -0.62917313\n",
      "  1.86012257 -1.59640257  1.57194858 -1.34092392 -0.79277738 -1.30389849]\n",
      "Example test boxes 1: [['0.78125' '0.91875' '0.075833336' '0.4525' '0.675625' '0.955'\n",
      "  '0.16916667' '0.4425']]\n",
      "Example test subject labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example test object labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example test relationship labels: [0 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print ('Example train 1: {}'.format(X_train[0]))\n",
    "print ('Example test boxes 1: {}'.format(y_train[0][0]))\n",
    "print ('Example test subject labels: {}'.format(y_train[1][0]))\n",
    "print ('Example test object labels: {}'.format(y_train[2][0]))\n",
    "print ('Example test relationship labels: {}'.format(y_train[3][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PriorProbability(keras.initializers.Initializer):\n",
    "    \"\"\" Apply a prior probability to the weights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, probability=0.01):\n",
    "        self.probability = probability\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'probability': self.probability\n",
    "        }\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        # set bias to -log((1 - p)/p) for foreground\n",
    "        result = np.ones(shape, dtype=dtype) * -math.log((1 - self.probability) / self.probability)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DeepClassifyRegressModel(input_shape, subject_output_class_size, object_output_class_size,\n",
    "                             relationship_output_class_size,\n",
    "                             output_reg_size, prior_probability = 0.01, \n",
    "                             drop_out=0.5,\n",
    "                             disable_regress=True):\n",
    "    \"\"\"\n",
    "    Model is regular deep neural network with 4 outputs.\n",
    "    output1: Regression with two bounding boxes of size (N, 4)\n",
    "    output2: Object classifcation of size(N, 61)\n",
    "    output3: Subject classifcation of size(N, 61)\n",
    "    output3: Relationship classifcation of size(N, 10)\n",
    "    \"\"\"\n",
    "    main_input = Input(shape=input_shape)\n",
    "\n",
    "    # Layer 1 Relu - Norm - Dropout\n",
    "    if disable_regress is False:\n",
    "        bias_initializer=PriorProbability(probability=prior_probability)\n",
    "    else:\n",
    "        bias_initializer='zeros'\n",
    "    shared_model = Dense(units=1024, input_shape=input_shape, \n",
    "                        kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
    "                        bias_initializer=bias_initializer)(main_input)                   \n",
    "    shared_model = BatchNormalization()(shared_model)\n",
    "    shared_model = Activation('relu')(shared_model)\n",
    "    shared_model = Dropout(drop_out)(shared_model)\n",
    "    \n",
    "    # Layer 2\n",
    "    if disable_regress is False:\n",
    "        bias_initializer=PriorProbability(probability=prior_probability)\n",
    "    shared_model = Dense(units=256,\n",
    "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
    "                         bias_initializer=PriorProbability(probability=prior_probability))(shared_model)\n",
    "    shared_model = BatchNormalization()(shared_model)\n",
    "    shared_model = Activation('relu')(shared_model)\n",
    "    shared_model = Dropout(drop_out)(shared_model)\n",
    "    \n",
    "    # Layer 3\n",
    "    \"\"\"\n",
    "    if disable_regress is False:\n",
    "        bias_initializer=PriorProbability(probability=prior_probability)\n",
    "    shared_model = Dense(units=128,\n",
    "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
    "                         bias_initializer=PriorProbability(probability=prior_probability))(shared_model)\n",
    "    shared_model = BatchNormalization()(shared_model)\n",
    "    shared_model = Activation('relu')(shared_model)\n",
    "    shared_model = Dropout(drop_out)(shared_model)\n",
    "    \"\"\"\n",
    "\n",
    "    # Regression branch\n",
    "    model_regression = None\n",
    "    if disable_regress is False:\n",
    "        model_regression = Dense(output_reg_size, activation=\"linear\", name=\"regression\")(shared_model)\n",
    "    \n",
    "    # Subject classification branch\n",
    "    model_subject_classify = Dense(subject_output_class_size)(shared_model)\n",
    "    model_subject_classify = Activation(tf.nn.softmax, name=\"classification_subject\")(model_subject_classify)\n",
    "    \n",
    "    # Object classification branch\n",
    "    model_object_classify = Dense(object_output_class_size)(shared_model)\n",
    "    model_object_classify = Activation(tf.nn.softmax, name=\"classification_object\")(model_object_classify)\n",
    "    \n",
    "    # 2 Layer for relationship, everything is the input\n",
    "    if disable_regress is False:\n",
    "        concat_layer = concatenate([model_regression, model_subject_classify, model_object_classify], axis=1)\n",
    "    else:\n",
    "        concat_layer = concatenate([shared_model, model_subject_classify, model_object_classify], axis=1)\n",
    "\n",
    "    if disable_regress is False:\n",
    "        bias_initializer=PriorProbability(probability=prior_probability)\n",
    "    relationship_model = Dense(units=128,\n",
    "                         kernel_initializer=keras.initializers.normal(mean=0.0, stddev=0.01, seed=None),\n",
    "                         bias_initializer=PriorProbability(probability=prior_probability))(concat_layer)\n",
    "    relationship_model = BatchNormalization()(relationship_model)\n",
    "    relationship_model = Activation('relu')(relationship_model)\n",
    "    relationship_model = Dropout(drop_out)(relationship_model)\n",
    "    \n",
    "    model_relationship_classify = Dense(relationship_output_class_size)(relationship_model)\n",
    "    model_relationship_classify = Activation(tf.nn.softmax, \n",
    "                                             name=\"classification_relationship\")(model_relationship_classify)\n",
    "    \n",
    "    outputs=[]\n",
    "    if model_regression is not None:\n",
    "        outputs=[model_regression]\n",
    "    model = Model(inputs=[main_input], outputs= outputs + [model_subject_classify, \n",
    "                                                model_object_classify, model_relationship_classify])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Compatible with tensorflow backend\n",
    "\n",
    "our_model.compile(optimizer=optimizer, loss=[focal_loss(alpha=.25, gamma=2)])\n",
    "'''\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_retinanet import losses\n",
    "def train_model(model, x_train, y_train, learn_rate=1e-5, epochs=32, batch_size=64, \n",
    "                disable_regress = True, verbose=1):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    Using as loss function and Adam optimizer\n",
    "    \"\"\"\n",
    "    loss_dict = {'classification_subject': 'categorical_crossentropy', # focal_loss()\n",
    "            'classification_object': 'categorical_crossentropy',  # focal_loss()\n",
    "            'classification_relationship': 'categorical_crossentropy' # focal_loss()\n",
    "                }\n",
    "    if disable_regress is False:\n",
    "       loss_dict['regression'] = 'mean_squared_error'\n",
    "    \n",
    "    model.compile(loss=loss_dict,\n",
    "        optimizer=keras.optimizers.adam(lr=learn_rate, clipnorm=0.001), metrics=['accuracy'])\n",
    "    return model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "        verbose=verbose, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (600,)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         615424      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          262400      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 61)           15677       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 61)           15677       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification_subject (Activat (None, 61)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "classification_object (Activati (None, 61)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 378)          0           dropout_2[0][0]                  \n",
      "                                                                 classification_subject[0][0]     \n",
      "                                                                 classification_object[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          48512       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           1290        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classification_relationship (Ac (None, 10)           0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 964,612\n",
      "Trainable params: 961,796\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n",
      "Train on 61860 samples, validate on 15465 samples\n",
      "Epoch 1/10\n",
      "61860/61860 [==============================] - 101s 2ms/step - loss: 8.6382 - classification_subject_loss: 3.2749 - classification_object_loss: 3.1968 - classification_relationship_loss: 2.1665 - classification_subject_acc: 0.2164 - classification_object_acc: 0.2200 - classification_relationship_acc: 0.2839 - val_loss: 6.2159 - val_classification_subject_loss: 2.3631 - val_classification_object_loss: 2.3378 - val_classification_relationship_loss: 1.5150 - val_classification_subject_acc: 0.3791 - val_classification_object_acc: 0.3752 - val_classification_relationship_acc: 0.4779\n",
      "Epoch 2/10\n",
      "61860/61860 [==============================] - 100s 2ms/step - loss: 6.4466 - classification_subject_loss: 2.4386 - classification_object_loss: 2.4329 - classification_relationship_loss: 1.5752 - classification_subject_acc: 0.3142 - classification_object_acc: 0.3129 - classification_relationship_acc: 0.4483 - val_loss: 5.4544 - val_classification_subject_loss: 2.0599 - val_classification_object_loss: 2.0617 - val_classification_relationship_loss: 1.3328 - val_classification_subject_acc: 0.3962 - val_classification_object_acc: 0.3922 - val_classification_relationship_acc: 0.5235\n",
      "Epoch 3/10\n",
      "61860/61860 [==============================] - 99s 2ms/step - loss: 6.0257 - classification_subject_loss: 2.2764 - classification_object_loss: 2.2778 - classification_relationship_loss: 1.4715 - classification_subject_acc: 0.3280 - classification_object_acc: 0.3271 - classification_relationship_acc: 0.4691 - val_loss: 5.1760 - val_classification_subject_loss: 1.9516 - val_classification_object_loss: 1.9541 - val_classification_relationship_loss: 1.2703 - val_classification_subject_acc: 0.4080 - val_classification_object_acc: 0.4032 - val_classification_relationship_acc: 0.5340\n",
      "Epoch 4/10\n",
      "61860/61860 [==============================] - 99s 2ms/step - loss: 5.8188 - classification_subject_loss: 2.1975 - classification_object_loss: 2.2002 - classification_relationship_loss: 1.4211 - classification_subject_acc: 0.3382 - classification_object_acc: 0.3363 - classification_relationship_acc: 0.4788 - val_loss: 5.0286 - val_classification_subject_loss: 1.8984 - val_classification_object_loss: 1.8984 - val_classification_relationship_loss: 1.2318 - val_classification_subject_acc: 0.4076 - val_classification_object_acc: 0.4088 - val_classification_relationship_acc: 0.5493\n",
      "Epoch 5/10\n",
      "61860/61860 [==============================] - 99s 2ms/step - loss: 5.6673 - classification_subject_loss: 2.1470 - classification_object_loss: 2.1425 - classification_relationship_loss: 1.3778 - classification_subject_acc: 0.3446 - classification_object_acc: 0.3428 - classification_relationship_acc: 0.4872 - val_loss: 4.9320 - val_classification_subject_loss: 1.8618 - val_classification_object_loss: 1.8646 - val_classification_relationship_loss: 1.2056 - val_classification_subject_acc: 0.4129 - val_classification_object_acc: 0.4111 - val_classification_relationship_acc: 0.5501\n",
      "Epoch 6/10\n",
      "61860/61860 [==============================] - 99s 2ms/step - loss: 5.5571 - classification_subject_loss: 2.1036 - classification_object_loss: 2.0987 - classification_relationship_loss: 1.3548 - classification_subject_acc: 0.3494 - classification_object_acc: 0.3510 - classification_relationship_acc: 0.4913 - val_loss: 4.8644 - val_classification_subject_loss: 1.8403 - val_classification_object_loss: 1.8407 - val_classification_relationship_loss: 1.1834 - val_classification_subject_acc: 0.4156 - val_classification_object_acc: 0.4151 - val_classification_relationship_acc: 0.5557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "61860/61860 [==============================] - 99s 2ms/step - loss: 5.4710 - classification_subject_loss: 2.0699 - classification_object_loss: 2.0720 - classification_relationship_loss: 1.3290 - classification_subject_acc: 0.3551 - classification_object_acc: 0.3570 - classification_relationship_acc: 0.4982 - val_loss: 4.8236 - val_classification_subject_loss: 1.8232 - val_classification_object_loss: 1.8231 - val_classification_relationship_loss: 1.1773 - val_classification_subject_acc: 0.4197 - val_classification_object_acc: 0.4177 - val_classification_relationship_acc: 0.5578\n",
      "Epoch 8/10\n",
      "61860/61860 [==============================] - 99s 2ms/step - loss: 5.3928 - classification_subject_loss: 2.0391 - classification_object_loss: 2.0427 - classification_relationship_loss: 1.3110 - classification_subject_acc: 0.3632 - classification_object_acc: 0.3589 - classification_relationship_acc: 0.5055 - val_loss: 4.7830 - val_classification_subject_loss: 1.8095 - val_classification_object_loss: 1.8113 - val_classification_relationship_loss: 1.1621 - val_classification_subject_acc: 0.4230 - val_classification_object_acc: 0.4210 - val_classification_relationship_acc: 0.5615\n",
      "Epoch 9/10\n",
      "61860/61860 [==============================] - 99s 2ms/step - loss: 5.3312 - classification_subject_loss: 2.0174 - classification_object_loss: 2.0180 - classification_relationship_loss: 1.2959 - classification_subject_acc: 0.3711 - classification_object_acc: 0.3661 - classification_relationship_acc: 0.5099 - val_loss: 4.7433 - val_classification_subject_loss: 1.7964 - val_classification_object_loss: 1.7978 - val_classification_relationship_loss: 1.1491 - val_classification_subject_acc: 0.4248 - val_classification_object_acc: 0.4241 - val_classification_relationship_acc: 0.5652\n",
      "Epoch 10/10\n",
      "61860/61860 [==============================] - 99s 2ms/step - loss: 5.2708 - classification_subject_loss: 1.9978 - classification_object_loss: 1.9954 - classification_relationship_loss: 1.2777 - classification_subject_acc: 0.3697 - classification_object_acc: 0.3722 - classification_relationship_acc: 0.5146 - val_loss: 4.7210 - val_classification_subject_loss: 1.7868 - val_classification_object_loss: 1.7877 - val_classification_relationship_loss: 1.1465 - val_classification_subject_acc: 0.4235 - val_classification_object_acc: 0.4219 - val_classification_relationship_acc: 0.5682\n"
     ]
    }
   ],
   "source": [
    "# Get the model\n",
    "print (\"Input shape: {}\".format(X_train[0].shape))\n",
    "disable_regress = True\n",
    "model = DeepClassifyRegressModel(X_train[0].shape, subject_output_class_size=len(mlb_subject_object.classes_),\n",
    "                                 object_output_class_size=len(mlb_subject_object.classes_), \n",
    "                                 relationship_output_class_size=len(mlb_relationship.classes_),\n",
    "                                 output_reg_size=8,\n",
    "                                 disable_regress=disable_regress)\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "if disable_regress:\n",
    "    y_train_final = y_train[1:]   # Remove the regression y data.\n",
    "\n",
    "model_history = train_model(model, X_train, y_train_final, epochs=epochs, batch_size=batch_size, \n",
    "                            disable_regress=disable_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "Save the model that has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the weights.\n",
    "model.save_weights('stage2_model_epoch_10_weights.h5')\n",
    "model.save('stage2_model_epoch_10.h5')\n",
    "\n",
    "# Save the model architecture.\n",
    "with open('stage2_model.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "    \n",
    "# Save the MLB labels for later use.\n",
    "with open(\"mlb_subject_object.p\", \"wb\") as f:\n",
    "    f.write(pickle.dumps(mlb_subject_object))\n",
    "    \n",
    "with open(\"mlb_relationship.p\", \"wb\") as f:\n",
    "    f.write(pickle.dumps(mlb_relationship))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History keys: dict_keys(['val_classification_object_loss', 'classification_object_loss', 'classification_object_acc', 'val_classification_subject_acc', 'classification_subject_loss', 'loss', 'classification_relationship_loss', 'val_classification_object_acc', 'classification_relationship_acc', 'val_classification_relationship_loss', 'val_classification_relationship_acc', 'classification_subject_acc', 'val_loss', 'val_classification_subject_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFguCiIhksSCIiEjWH1xiKi6GYU/gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc716fcccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "print ('History keys: {}'.format(model_history.history.keys()))\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs), model_history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epochs), model_history.history[\"val_loss\"], label=\"val_loss\")\n",
    "#plt.plot(np.arange(0, epochs), model_history.history[\"val_regression_loss\"], label=\"val_regression_loss\")\n",
    "#plt.plot(np.arange(0, epochs), model_history.history[\"val_classification_loss\"], label=\"val_classification_loss\")\n",
    "#plt.plot(np.arange(0, epochs), model_history.history[\"classification_acc\"], label=\"classification_acc\")\n",
    "#plt.plot(np.arange(0, epochs), model_history.history[\"val_classification_acc\"], label=\"val_classification_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(\"model_training_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the saved model.\n",
    "saved_model = 'stage2_model_epoch_10.h5'\n",
    "saved_model_weights = 'stage2_model_epoch_10_weights.h5'\n",
    "json_model = 'stage2_model.json'\n",
    "infer_model = load_model(saved_model, custom_objects={'PriorProbability': PriorProbability, \n",
    "                                                      'focal_loss_fixed': focal_loss(),\n",
    "                                                      'softmax': tf.nn.softmax})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time:  0.15233469009399414\n",
      "Prediction : [array([[  6.02102373e-04,   2.21070577e-03,   1.31887011e-02,\n",
      "          4.92396473e-04,   8.58862419e-04,   2.84634973e-03,\n",
      "          1.33239683e-02,   3.89685272e-04,   1.17358528e-01,\n",
      "          5.10651059e-03,   1.03185689e-02,   2.03294074e-03,\n",
      "          5.47081698e-03,   7.29360094e-04,   9.42295359e-04,\n",
      "          2.16439459e-03,   1.76329259e-03,   7.96559602e-02,\n",
      "          9.54606608e-02,   7.95995642e-04,   7.71315116e-03,\n",
      "          9.64853796e-04,   5.30107878e-03,   4.11033834e-04,\n",
      "          9.39340964e-02,   6.54627045e-04,   3.18299457e-02,\n",
      "          5.09191421e-04,   3.35259706e-01,   7.22447759e-04,\n",
      "          1.26541185e-03,   6.12469506e-04,   5.45131450e-04,\n",
      "          1.00817317e-02,   1.20352842e-02,   1.80330628e-03,\n",
      "          5.44328301e-04,   3.22001847e-03,   6.33628806e-04,\n",
      "          6.02617720e-03,   9.85919498e-03,   2.23885849e-02,\n",
      "          6.31748757e-04,   1.47333229e-03,   3.11050192e-03,\n",
      "          8.51860968e-04,   9.89075517e-04,   1.17008644e-03,\n",
      "          8.02437589e-02,   2.84849375e-04,   1.27144309e-03,\n",
      "          1.09100819e-03,   1.03340985e-03,   5.47740201e-04,\n",
      "          4.40334872e-04,   5.07819990e-04,   1.09689531e-03,\n",
      "          6.70839800e-04,   6.72297436e-04,   1.01335708e-03,\n",
      "          8.72114615e-04]], dtype=float32), array([[  1.03073136e-03,   8.31912737e-04,   1.31060369e-02,\n",
      "          7.73423933e-04,   5.75218815e-04,   3.41002061e-03,\n",
      "          8.51631071e-03,   4.17636387e-04,   1.09230436e-01,\n",
      "          6.87030097e-03,   8.88937805e-03,   1.04077742e-03,\n",
      "          7.79791782e-03,   3.75237170e-04,   2.15445878e-04,\n",
      "          8.70133401e-04,   2.07060901e-03,   1.00202844e-01,\n",
      "          8.80364329e-02,   5.12906234e-04,   1.01375179e-02,\n",
      "          8.15775828e-04,   4.58793389e-03,   5.14301937e-04,\n",
      "          9.00300443e-02,   5.03895339e-04,   2.12300867e-02,\n",
      "          3.10845440e-04,   3.72403741e-01,   6.09249284e-04,\n",
      "          8.23511917e-04,   4.37059964e-04,   6.23890548e-04,\n",
      "          6.53152075e-03,   1.33975502e-02,   4.03649610e-04,\n",
      "          4.81629133e-04,   4.47709020e-03,   2.31672049e-04,\n",
      "          5.98728703e-03,   1.97958127e-02,   1.20146926e-02,\n",
      "          3.30796058e-04,   9.26019449e-04,   4.70359391e-03,\n",
      "          2.71597295e-03,   4.55171830e-04,   1.22138090e-03,\n",
      "          6.18061945e-02,   7.14152993e-04,   1.22992706e-03,\n",
      "          3.44124099e-04,   4.50210297e-04,   6.41712744e-04,\n",
      "          3.41917417e-04,   4.13319678e-04,   3.38045968e-04,\n",
      "          6.84142113e-04,   4.86521225e-04,   5.38415625e-04,\n",
      "          5.35933359e-04]], dtype=float32), array([[ 0.05959528,  0.02583444,  0.31692618,  0.03569566,  0.021261  ,\n",
      "         0.34186253,  0.13606158,  0.04391984,  0.00736052,  0.01148295]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "prediction = infer_model.predict_on_batch(np.expand_dims(X_test[0], axis=0))\n",
    "print(\"processing time: \", time.time() - start)\n",
    "print ('Prediction : {}'.format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model prediction to labels for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject label prediction: ([-1, -1, -1, -1, -1, -1, -1, -1], ('/m/04yx4', '/m/04yx4', 'is'), 0.34984199206034344)\n"
     ]
    }
   ],
   "source": [
    "def get_score(subject_prediction, object_prediction, relationship_prediction, disable_regress=True):\n",
    "    subject_max = float(np.amax(subject_prediction))\n",
    "    object_max = float(np.amax(object_prediction))\n",
    "    relationship_max = float(np.amax(relationship_prediction))\n",
    "    return (subject_max + object_max + relationship_max)/3.0\n",
    "\n",
    "def get_label(lb, softmax_vector):\n",
    "    a = np.asarray(softmax_vector).reshape(-1)\n",
    "    b = np.zeros_like(a)\n",
    "    b[np.argmax(a)] = 1\n",
    "    return lb.inverse_transform(b.reshape(1, -1))[0]\n",
    "\n",
    "def convert_prediction_to_label(lb_subject_object, lb_relationship_object, prediction, disable_regress=True):\n",
    "    # regress output\n",
    "    start_idx = 0\n",
    "    if disable_regress is False:\n",
    "        boxes = prediction[start_idx]\n",
    "        start_idx +=1\n",
    "\n",
    "    label_subject_probs = prediction[start_idx]\n",
    "    label_subject = get_label(lb_subject_object, prediction[start_idx])\n",
    "    label_object = get_label(lb_subject_object, prediction[start_idx + 1])\n",
    "    label_relationship = get_label(lb_relationship_object, prediction[start_idx + 2])\n",
    "    score = get_score(prediction[start_idx], prediction[start_idx + 1], prediction[start_idx + 2])\n",
    "    if disable_regress is False:\n",
    "        return (boxes.reshape(-1).tolist(), (label_subject, label_object, label_relationship), score)\n",
    "    else:\n",
    "        return ([-1]*8, (label_subject, label_object, label_relationship), score)\n",
    "\n",
    "print ('Subject label prediction: {}'.format(convert_prediction_to_label(mlb_subject_object,                                                 \n",
    "                                                                         mlb_relationship,\n",
    "                                                                         prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (16645, 600)\n",
      "processing time:  0.777240514755249\n"
     ]
    }
   ],
   "source": [
    "# Get prediction for test set to evaluate score.\n",
    "print ('X_test shape: {}'.format(X_test.shape))\n",
    "start = time.time()\n",
    "predictions = infer_model.predict(X_test)\n",
    "print(\"processing time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction[0] shape: (16645, 61), prediction[1] shape: (16645, 61), prediction[2] shape: (16645, 10)\n"
     ]
    }
   ],
   "source": [
    "print ('Prediction[0] shape: {}, prediction[1] shape: {}, prediction[2] shape: {}'.format(\n",
    "    predictions[0].shape, predictions[1].shape, predictions[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entry_for_eval(fid, predictions, lb_subject_object, lb_relationship_object, disable_regress=True):\n",
    "    boxes_labels_tuple = convert_prediction_to_label(lb_subject_object, lb_relationship_object, predictions,\n",
    "                                                    disable_regress=disable_regress)\n",
    "    return [fid, boxes_labels_tuple[1][0], boxes_labels_tuple[1][1]] + boxes_labels_tuple[0] + \\\n",
    "            [boxes_labels_tuple[1][2]] + [boxes_labels_tuple[2]]\n",
    "\n",
    "def process_test_set_predictions(test_dataset, X_test, infer_model, \n",
    "                                 lb_subject_object, lb_relationship_object,\n",
    "                                 disable_regress=True):\n",
    "    print ('X_test shape: {}'.format(X_test.shape))\n",
    "    start = time.time()\n",
    "    predictions = infer_model.predict(X_test)\n",
    "    print(\"processing time: \", time.time() - start)\n",
    "    ret_list = []\n",
    "    print ('processing entry count: {}'.format(len(test_dataset['id'])))\n",
    "    for i in range(0, len(test_dataset['id'])):\n",
    "        fid = test_dataset['id'][i]\n",
    "        if disable_regress is False:\n",
    "            eval_output = get_entry_for_eval(fid, \n",
    "                                             [predictions[0][i],\n",
    "                                              predictions[1][i].reshape(1, -1), \n",
    "                                              predictions[2][i].reshape(1, -1), \n",
    "                                              predictions[3][i].reshape(1, -1)], lb_subject_object, \n",
    "                                              lb_relationship_object)\n",
    "            ret_list.append(eval_output)\n",
    "        else:\n",
    "            eval_output = get_entry_for_eval(fid, \n",
    "                                             [predictions[0][i].reshape(1, -1), \n",
    "                                              predictions[1][i].reshape(1, -1), \n",
    "                                              predictions[2][i].reshape(1, -1)], lb_subject_object, \n",
    "                                              lb_relationship_object, disable_regress=disable_regress)\n",
    "            ret_list.append(eval_output)\n",
    "\n",
    "    return ret_list\n",
    "\n",
    "def ouput_validation_csv(validation_list, csv_file, prefix='validation', disable_regress=True):\n",
    "    csv_file_path = os.path.join(prefix, csv_file)\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf8') as f:\n",
    "        write_one_extra = False\n",
    "        writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(\n",
    "    \"ImageID,LabelName1,LabelName2,XMin1,XMax1,YMin1,YMax1,XMin2,XMax2,YMin2,YMax2,RelationshipLabel,Score\".split(','))\n",
    "        for entry in validation_list:\n",
    "            writer.writerow(entry)\n",
    "            if write_one_extra is False:\n",
    "                writer.writerow(entry)  # Hack to write twice to fix error in ooid_vrd_challenge_evaluation.py\n",
    "                write_one_extra = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (16645, 600)\n",
      "processing time:  0.8419055938720703\n",
      "processing entry count: 16645\n"
     ]
    }
   ],
   "source": [
    "disable_regress=True\n",
    "validation_list = process_test_set_predictions(model_test_dataset, X_test, infer_model, \n",
    "                                               mlb_subject_object, mlb_relationship, \n",
    "                                               disable_regress=disable_regress)\n",
    "ouput_validation_csv(validation_list, csv_file='stage2_model_epoch_10_testset_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter input csv for evalulation\n",
    "\n",
    "This is mentioned here:\n",
    "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/challenge_evaluation.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_ground_truth_csv(prefix='data/raw', train_csv_fname = 'challenge-2018-train-vrd.csv', \n",
    "                            test_csv_fname = 'validation/stage2_model_epoch_10_testset_val.csv',\n",
    "                            filtered_csv_fname = 'validation/filtered-challenge-2018-train-vrd.csv'):\n",
    "    \n",
    "    test_fid_set = set()\n",
    "    with open(test_csv_fname, mode='r', encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            test_fid_set.add(row[0])\n",
    "    \n",
    "    filtered_truth_rows = []\n",
    "    with open(os.path.join(prefix, train_csv_fname), mode='r', encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        for row in rows:\n",
    "            if row[0] in test_fid_set:\n",
    "                filtered_truth_rows.append(row)\n",
    "        \n",
    "    with open(filtered_csv_fname, mode='w', newline='', encoding='utf8') as f:\n",
    "        writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for entry in filtered_truth_rows:\n",
    "            writer.writerow(entry)\n",
    "            \n",
    "    return filtered_truth_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered set size: 109699\n"
     ]
    }
   ],
   "source": [
    "training_csv = 'challenge-2018-train-vrd.csv'\n",
    "validation_csv = 'validation/stage2_model_epoch_10_testset_val.csv'\n",
    "filtered_csv_fname = 'validation/filtered-challenge-2018-train-vrd.csv'\n",
    "filtered_ground_truth_rows = filter_ground_truth_csv(prefix='data/raw', \n",
    "                                                     train_csv_fname = 'challenge-2018-train-vrd.csv', \n",
    "                                                     test_csv_fname = validation_csv,\n",
    "                                                     filtered_csv_fname = filtered_csv_fname)\n",
    "print ('Filtered set size: {}'.format(len(filtered_ground_truth_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers for mAP calculation without using IOU for now\n",
    "\n",
    "Only measure triplet detection accuracy per class and across all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_triplet_to_image_id_dict_from_csv(csv_fname):\n",
    "    ret_dict = {}\n",
    "    \n",
    "    with open(csv_fname, mode='r', encoding='utf8') as f:\n",
    "        rows = csv.reader(f)\n",
    "        header_process = False\n",
    "        relationship_idx = -1\n",
    "        for row in rows:\n",
    "            if header_process is False:\n",
    "                print ('header for {}: {}'.format(csv_fname, row))\n",
    "                relationship_idx = row.index('RelationshipLabel')\n",
    "                header_process = True\n",
    "                continue\n",
    "            fid = row[0]\n",
    "            subject_class = row[1]\n",
    "            object_class = row[2]\n",
    "            relationship_class = row[relationship_idx]\n",
    "            boxes = row[3:11]\n",
    "            k = (subject_class, object_class, relationship_class)\n",
    "            if k in ret_dict:\n",
    "                if fid in ret_dict[k]:\n",
    "                    ret_dict[k][fid].append(boxes)\n",
    "                else:\n",
    "                    ret_dict[k][fid] = [boxes]\n",
    "            else:\n",
    "                ret_dict[k] = {fid: [boxes]}\n",
    "    return ret_dict\n",
    "\n",
    "def get_triplet_to_image_id_dict_from_data_set(model_data_input):\n",
    "    \"\"\"\n",
    "    When not considering bounding box data dimension for train and test set we only have a \n",
    "    constrained set of triplets. Get them for evaluation.\n",
    "    \"\"\"\n",
    "    ret_dict = {}\n",
    "\n",
    "    for fid, boxes, labels_orig in zip(model_data_input['id'], model_data_input['boxes'], \n",
    "                                       model_data_input['labels_orig']):\n",
    "        k = labels_orig\n",
    "        if k not in ret_dict:\n",
    "            ret_dict[k] = {}\n",
    "\n",
    "        if fid not in ret_dict[k]:\n",
    "            ret_dict[k][fid] = []\n",
    "  \n",
    "        ret_dict[k][fid].append(boxes)\n",
    "\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header for validation/stage2_model_epoch_10_testset_val.csv: ['ImageID', 'LabelName1', 'LabelName2', 'XMin1', 'XMax1', 'YMin1', 'YMax1', 'XMin2', 'XMax2', 'YMin2', 'YMax2', 'RelationshipLabel', 'Score']\n"
     ]
    }
   ],
   "source": [
    "ground_truth_triplet_dict = get_triplet_to_image_id_dict_from_data_set(model_data_input=model_test_dataset)\n",
    "model_test_triplet_dict, model_test_rel_dict = get_triplets_from_dataset(model_test_dataset)\n",
    "testset_triplet_dict = get_triplet_to_image_id_dict_from_csv(csv_fname=validation_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model test triplet keys length: 231\n",
      "testset triplet_keys lenth: 85\n"
     ]
    }
   ],
   "source": [
    "print ('model test triplet keys length: {}'.format(len(ground_truth_triplet_dict.keys())))\n",
    "print ('testset triplet_keys lenth: {}'.format(len(testset_triplet_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_per_class_precision_recall_dict(ground_truth_triplet_dict, testset_triplet_dict):\n",
    "    class_dict = {}\n",
    "    for triplet, v in testset_triplet_dict.items():\n",
    "        #print('Triplet: {}'.format(triplet))\n",
    "        detection_count = len(v.keys())        \n",
    "        true_positives = 0.0\n",
    "        ground_truth_count = 0.0\n",
    "        if triplet in ground_truth_triplet_dict:\n",
    "            result_fid_set = set(v.keys())\n",
    "            ground_fid_set = set(ground_truth_triplet_dict[triplet].keys())\n",
    "            ground_truth_count  = len(ground_fid_set)\n",
    "            true_positives = len(result_fid_set.intersection(ground_fid_set))\n",
    "        #print ('+ive: {}, detection_count: {}'.format(true_positives, detection_count))\n",
    "        precision = float(true_positives)/float(detection_count)\n",
    "        if ground_truth_count != 0.0:\n",
    "            recall = float(true_positives)/float(ground_truth_count)\n",
    "        else:\n",
    "            recall = None  # Invalid triplet!.\n",
    "        class_dict[triplet] = (precision, recall)\n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triplet_precision_recall = get_per_class_precision_recall_dict(ground_truth_triplet_dict, testset_triplet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing label count: 0\n"
     ]
    }
   ],
   "source": [
    "xy_list, train_data_label_tuple, label_dict = process_raw_csv_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per triplet precision and recall\n",
    "\n",
    "List the precision and recall obtained per triplet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man-holds-Bottle:0.0,None\n",
      "Woman-at-Table:0.0,None\n",
      "Man-at-Table:0.15,None\n",
      "Chair-at-Table:0.5,None\n",
      "Man-on-Chair:0.0,None\n",
      "Man-holds-Guitar:0.0,None\n"
     ]
    }
   ],
   "source": [
    "for k, v in triplet_precision_recall.items():\n",
    "    #print ('Triplet: {}'.format(k))\n",
    "    if v[1] is not None:\n",
    "        print ('{}-{}-{}:{},{}'.format(label_dict[k[0]], k[2], label_dict[k[1]], \n",
    "            round(float(v[0]), 2), v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
